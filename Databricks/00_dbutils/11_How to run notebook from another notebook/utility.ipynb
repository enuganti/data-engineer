{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaab8480-a45c-41ca-b684-0471c8029dd0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Required Import Functions."
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from delta.tables import *\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3e15fec-5162-4b02-ae06-f51a2251ae5b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Defining Schema."
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, LongType\n",
    "\n",
    "# Define custom schema for the nested structure\n",
    "AddSchema = StructType([StructField('country', StringType(), False),\n",
    "                        StructField('user', StringType(), False),\n",
    "                        StructField('Location', StringType(), False),\n",
    "                        StructField('Zipcode', StringType(), False),]\n",
    "                      )\n",
    "# Define the main schema including the nested structure\n",
    "schema_json = StructType([StructField('source', StringType(), False),\n",
    "                          StructField('description', StringType(), False),\n",
    "                          StructField('input_timestamp', LongType(), False),\n",
    "                          StructField('last_update_timestamp', LongType(), False),\n",
    "                          StructField('Address', AddSchema)]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76a02404-b95a-4235-a06c-91dcfc5f8dc5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function to read the file from Bronze Layer."
    }
   },
   "outputs": [],
   "source": [
    "# Function to read the data from Bronze layer using custom schema\n",
    "def read_from_bronze(bronze_layer_path):\n",
    "  df = spark.read.option(\"multiLine\", True).schema(schema_json).json(bronze_layer_path)\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utility",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
