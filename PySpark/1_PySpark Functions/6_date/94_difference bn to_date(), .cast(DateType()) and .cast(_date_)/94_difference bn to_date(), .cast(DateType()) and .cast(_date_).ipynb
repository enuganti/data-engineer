{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6432ff1e-f1d9-4e86-97bf-5f26a43382fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Refer below video's in \"PySpark playlist\" on \"to_date()\"**\n",
    "\n",
    "- 91_date_format( ) | to_date( ) | to_timestamp( ) | date to string & string to date #pyspark PART 91\n",
    "- 92_How to convert string to date format using to_date? | #pyspark PART 92\n",
    "- 93_How to convert string, timestamp to date using to_date() | #pyspark PART 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73686bc7-a3ee-4770-9ba6-d3a4862283e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1) to_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc0e0383-4abd-4dc7-9de1-1048b9496611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "✅ **to_date()** function is used to format a **\"date string\" (or) \"timestamp string\" column** into the **\"Date\" Type column** using a **specified format**.\n",
    "\n",
    "✅ If the **format is not provide**, to_date() takes the **default value as 'yyyy-MM-dd'**.\n",
    "\n",
    "✅ Extracts only the **date** portion **(removes time part if present)**.\n",
    "\n",
    "✅ Returns **NULL** if the format does **not match**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f058d446-56e9-4396-a744-bf12fdef88d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **Syntax:**\n",
    "\n",
    "     to_date(column,format)\n",
    "     to_date(col(\"string_column\"),\"MM-dd-yyyy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "401b7a8f-b2ec-4ad6-b345-9f60c940edad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "##### to_date()\n",
    "\n",
    "1) Converting a **String** Column with **Default Format**.\n",
    "   - If your **date strings** follow the **default** format **\"yyyy-MM-dd\"**, you can simply apply **to_date without specifying a format**.\n",
    "\n",
    "2) Converting a **String** Column with a **Custom Format**\n",
    "\n",
    "   - If your **date strings** are in a **different** format (e.g., **\"MM/dd/yyyy\"**), you **must specify the format** in the **to_date** function.\n",
    "\n",
    "|      col_name\t        |         format                   | default format: yyyy-MM-dd  |  After to_date(col_name, \"yyyy-MM-dd\") | correct format |\n",
    "|-----------------------|----------------------------------|-----------------------------|----------------------------------------|----------------|\n",
    "| \"2024-03-06\"\t        |  to_date(\"2024-03-06\")           |      Matching               |         2024-03-06 (Date)              | to_date(\"2024-03-06\") |\n",
    "| \"06-03-2024\"\t        |  to_date(\"06-03-2024\")           |      Not Matching           |       NULL (Format mismatch)           | to_date(\"06-03-2024\", \"dd-MM-yyyy\") |\n",
    "| \"2024-03-06 12:30:00\" |\t to_date(\"2024-03-06 12:30:00\")  |      Not Matching           |      2024-03-06 (Time removed)         | to_date(\"2024-03-06 12:30:00\", \"yyyy-MM-dd HH:mm:ss\") |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48646808-18cf-481f-b1b8-aeb603b22d52",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "import required functions"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2be7392-1567-4ddd-80ee-3299fae535bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Converting a \"String\" Column with \"Default Format\"\n",
    "\n",
    "- If your **date strings** follow the **default** format **\"yyyy-MM-dd\"**, you can simply apply **to_date without specifying a format**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd5de1bd-c9b5-4cd2-9137-acd939101e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ts_format_01</th><th>ts_format_02</th><th>ts_format_03</th><th>ts_format_04</th><th>ts_format_05</th><th>date_parsed_01</th><th>date_parsed_02</th><th>date_parsed_03</th><th>date_parsed_04</th><th>date_parsed_05</th></tr></thead><tbody><tr><td>2021-12-01</td><td>12/01/2021</td><td>25/04/2023 2:00</td><td>6-Feb-23</td><td>2021-07-24 12:01:19.335</td><td>2021-12-01</td><td>2021-12-01</td><td>2023-04-25</td><td>2023-02-06</td><td>2021-07-24</td></tr><tr><td>2022-01-15</td><td>01/15/2022</td><td>26/04/2023 6:01</td><td>1-Mar-22</td><td>2019-07-22 13:02:20.220</td><td>2022-01-15</td><td>2022-01-15</td><td>2023-04-26</td><td>2022-03-01</td><td>2019-07-22</td></tr><tr><td>2023-03-20</td><td>03/20/2023</td><td>20/01/2020 4:01</td><td>9-Apr-24</td><td>2021-07-25 03:03:13.098</td><td>2023-03-20</td><td>2023-03-20</td><td>2020-01-20</td><td>2024-04-09</td><td>2021-07-25</td></tr><tr><td>2024-06-28</td><td>05/25/2024</td><td>26/04/2023 2:02</td><td>8-May-20</td><td>2023-09-25 15:33:43.054</td><td>2024-06-28</td><td>2024-05-25</td><td>2023-04-26</td><td>2020-05-08</td><td>2023-09-25</td></tr><tr><td>2025-09-12</td><td>07/20/2025</td><td>25/04/2023 5:02</td><td>7-Jun-21</td><td>2024-05-25 23:53:53.023</td><td>2025-09-12</td><td>2025-07-20</td><td>2023-04-25</td><td>2021-06-07</td><td>2024-05-25</td></tr><tr><td>2025-03-22</td><td>09/29/2020</td><td>25/04/2023 9:03</td><td>5-Jul-23</td><td>2024-04-12 13:33:53.323</td><td>2025-03-22</td><td>2020-09-29</td><td>2023-04-25</td><td>2023-07-05</td><td>2024-04-12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2021-12-01",
         "12/01/2021",
         "25/04/2023 2:00",
         "6-Feb-23",
         "2021-07-24 12:01:19.335",
         "2021-12-01",
         "2021-12-01",
         "2023-04-25",
         "2023-02-06",
         "2021-07-24"
        ],
        [
         "2022-01-15",
         "01/15/2022",
         "26/04/2023 6:01",
         "1-Mar-22",
         "2019-07-22 13:02:20.220",
         "2022-01-15",
         "2022-01-15",
         "2023-04-26",
         "2022-03-01",
         "2019-07-22"
        ],
        [
         "2023-03-20",
         "03/20/2023",
         "20/01/2020 4:01",
         "9-Apr-24",
         "2021-07-25 03:03:13.098",
         "2023-03-20",
         "2023-03-20",
         "2020-01-20",
         "2024-04-09",
         "2021-07-25"
        ],
        [
         "2024-06-28",
         "05/25/2024",
         "26/04/2023 2:02",
         "8-May-20",
         "2023-09-25 15:33:43.054",
         "2024-06-28",
         "2024-05-25",
         "2023-04-26",
         "2020-05-08",
         "2023-09-25"
        ],
        [
         "2025-09-12",
         "07/20/2025",
         "25/04/2023 5:02",
         "7-Jun-21",
         "2024-05-25 23:53:53.023",
         "2025-09-12",
         "2025-07-20",
         "2023-04-25",
         "2021-06-07",
         "2024-05-25"
        ],
        [
         "2025-03-22",
         "09/29/2020",
         "25/04/2023 9:03",
         "5-Jul-23",
         "2024-04-12 13:33:53.323",
         "2025-03-22",
         "2020-09-29",
         "2023-04-25",
         "2023-07-05",
         "2024-04-12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ts_format_01",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts_format_02",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts_format_03",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts_format_04",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts_format_05",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_parsed_01",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "date_parsed_02",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "date_parsed_03",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "date_parsed_04",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "date_parsed_05",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample data with date in \"MM/dd/yyyy\" format\n",
    "data = [(\"2021-12-01\", \"12/01/2021\", \"25/04/2023 2:00\", \"6-Feb-23\", \"2021-07-24 12:01:19.335\"),\n",
    "        (\"2022-01-15\", \"01/15/2022\", \"26/04/2023 6:01\", \"1-Mar-22\", \"2019-07-22 13:02:20.220\"),\n",
    "        (\"2023-03-20\", \"03/20/2023\", \"20/01/2020 4:01\", \"9-Apr-24\", \"2021-07-25 03:03:13.098\"),\n",
    "        (\"2024-06-28\", \"05/25/2024\", \"26/04/2023 2:02\", \"8-May-20\", \"2023-09-25 15:33:43.054\"),\n",
    "        (\"2025-09-12\", \"07/20/2025\", \"25/04/2023 5:02\", \"7-Jun-21\", \"2024-05-25 23:53:53.023\"),\n",
    "        (\"2025-03-22\", \"09/29/2020\", \"25/04/2023 9:03\", \"5-Jul-23\", \"2024-04-12 13:33:53.323\")]\n",
    "\n",
    "columns = [\"ts_format_01\", \"ts_format_02\", \"ts_format_03\", \"ts_format_04\", \"ts_format_05\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_custom = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Convert string column to date type using custom format\n",
    "df_with_date = df_custom\\\n",
    "    .withColumn(\"date_parsed_01\", to_date(col(\"ts_format_01\"))) \\\n",
    "    .withColumn(\"date_parsed_02\", to_date(col(\"ts_format_02\"), \"MM/dd/yyyy\")) \\\n",
    "    .withColumn(\"date_parsed_03\", to_date(col(\"ts_format_03\"), \"dd/MM/yyyy H:mm\")) \\\n",
    "    .withColumn(\"date_parsed_04\", to_date(col(\"ts_format_04\"), \"d-MMM-yy\")) \\\n",
    "    .withColumn(\"date_parsed_05\", to_date(col(\"ts_format_05\")))\n",
    "display(df_with_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "496f0349-ecb1-4bda-9f82-5a4ec9bcf50e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2) .cast(DateType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8145916e-1ab5-40c9-ae84-be68d79fbeaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Features:**\n",
    "\n",
    "✅ Converts **string or timestamp** into a **date**, but assumes **\"yyyy-MM-dd\"** format.\n",
    "\n",
    "✅ If the format **does not match**, it returns **NULL**.\n",
    "\n",
    "✅ Equivalent to **.cast(\"date\")**, but more explicit in code.\n",
    "\n",
    "✅ **Cannot** specify a **custom format** like **to_date()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc7bbbf7-249f-4bbd-a634-971d6b524004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "| col_name\t | After col_name.cast(DateType()) |\n",
    "|------------|---------------------------------|\n",
    "| \"2024-03-06\"\t         | 2024-03-06 (Date)        |\n",
    "| \"06-03-2024\"\t         | NULL (Format mismatch)   |\n",
    "| \"2024-03-06 12:30:00\"\t | 2024-03-06 (Time removed)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e248e73c-d431-49ae-9242-789d7e5e286d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**a) Convert \"String\" column to \"DateType\"**\n",
    "- If a DataFrame contains a column with **date** values as **strings**, you can **cast** it to **DateType()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83ad38b9-1c73-46ff-b113-caec4608f139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     df = df.withColumn(\"date_column\", col(\"date_string\").cast(DateType()))\n",
    "                                    (or)\n",
    "     df_cast = df.withColumn(\"date_cast\", df.date_string.cast(DateType()))\n",
    "                                    (or)\n",
    "     df = df.withColumn('date_col', df['date_str'].cast(DateType()))                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77199bf6-2cdd-4b57-bdb3-3cc3ee66178b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_string</th><th>date_column</th></tr></thead><tbody><tr><td>2025-03-29</td><td>2025-03-29</td></tr><tr><td>2024-06-15</td><td>2024-06-15</td></tr><tr><td>2023-01-01</td><td>2023-01-01</td></tr><tr><td>2023-06-11</td><td>2023-06-11</td></tr><tr><td>2022-09-21</td><td>2022-09-21</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-03-29",
         "2025-03-29"
        ],
        [
         "2024-06-15",
         "2024-06-15"
        ],
        [
         "2023-01-01",
         "2023-01-01"
        ],
        [
         "2023-06-11",
         "2023-06-11"
        ],
        [
         "2022-09-21",
         "2022-09-21"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_column",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Sample Data\n",
    "data = [(\"2025-03-29\",), (\"2024-06-15\",), (\"2023-01-01\",), (\"2023-06-11\",), (\"2022-09-21\",)]\n",
    "df_date = spark.createDataFrame(data, [\"date_string\"])\n",
    "\n",
    "# Convert the String column to DateType\n",
    "df_date_type = df_date.withColumn(\"date_column\", col(\"date_string\").cast(DateType()))\n",
    "display(df_date_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8815efb-f7ec-4762-9dcb-064fa925aa67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**b) Convert \"Timestamp String\" Column to \"DateType\"**\n",
    "- If a column contains **TimestampType** values, casting it to **DateType()** will **remove** the **time portion**.\n",
    "- If your DataFrame has a **timestamp string** column (for example, **'yyyy-MM-dd HH:mm:ss'**) and you only need the **date** portion, you can **cast** it to **DateType**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2735238c-c2f8-4a23-a38a-69760350641e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"timestamp_col\":215},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756046200038}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>timestamp_col</th><th>date_col</th></tr></thead><tbody><tr><td>1</td><td>2025-08-26T07:54:17.220Z</td><td>2025-08-26</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "2025-08-26T07:54:17.220Z",
         "2025-08-26"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp_col",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "df_ts = spark.createDataFrame([(1,)], [\"id\"])\n",
    "\n",
    "# Add a Timestamp Column\n",
    "df_ts_curr = df_ts.withColumn(\"timestamp_col\", current_timestamp())\n",
    "\n",
    "# Convert to DateType\n",
    "df_ts_curr_date = df_ts_curr.withColumn(\"date_col\", col(\"timestamp_col\").cast(DateType()))\n",
    "display(df_ts_curr_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24189e52-a014-45f3-a2a7-8efa7c887d5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>timestamp_str</th><th>date_only</th></tr></thead><tbody><tr><td>2025-03-29 14:30:45</td><td>2025-03-29</td></tr><tr><td>2025-04-01 08:15:00</td><td>2025-04-01</td></tr><tr><td>2024-06-11 18:25:55</td><td>2024-06-11</td></tr><tr><td>2023-08-17 22:55:35</td><td>2023-08-17</td></tr><tr><td>2025-04-01 20:45:22</td><td>2025-04-01</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-03-29 14:30:45",
         "2025-03-29"
        ],
        [
         "2025-04-01 08:15:00",
         "2025-04-01"
        ],
        [
         "2024-06-11 18:25:55",
         "2024-06-11"
        ],
        [
         "2023-08-17 22:55:35",
         "2023-08-17"
        ],
        [
         "2025-04-01 20:45:22",
         "2025-04-01"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "timestamp_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_only",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Sample data with timestamp strings\n",
    "data = [(\"2025-03-29 14:30:45\",),\n",
    "        (\"2025-04-01 08:15:00\",),\n",
    "        (\"2024-06-11 18:25:55\",),\n",
    "        (\"2023-08-17 22:55:35\",),\n",
    "        (\"2025-04-01 20:45:22\",)]\n",
    "        \n",
    "columns = [\"timestamp_str\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_ts_str = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Cast the timestamp string column to DateType\n",
    "df_ts_cast = df_ts_str.withColumn(\"date_only\", col(\"timestamp_str\").cast(DateType()))\n",
    "display(df_ts_cast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c86203eb-5b1d-487d-a15e-f85c7a33cae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**c) Convert \"Custom Format String\" to \"DateType\"**\n",
    "- If the **string** format is **not yyyy-MM-dd, to_date()** is needed before **casting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac8329fe-66e6-4cbb-86b5-da354007c9f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_string</th><th>date_column</th></tr></thead><tbody><tr><td>03-29-2025</td><td>2025-03-29</td></tr><tr><td>06-15-2024</td><td>2024-06-15</td></tr><tr><td>09-25-2023</td><td>2023-09-25</td></tr><tr><td>02-10-2022</td><td>2022-02-10</td></tr><tr><td>04-22-2024</td><td>2024-04-22</td></tr><tr><td>07-03-2021</td><td>2021-07-03</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "03-29-2025",
         "2025-03-29"
        ],
        [
         "06-15-2024",
         "2024-06-15"
        ],
        [
         "09-25-2023",
         "2023-09-25"
        ],
        [
         "02-10-2022",
         "2022-02-10"
        ],
        [
         "04-22-2024",
         "2024-04-22"
        ],
        [
         "07-03-2021",
         "2021-07-03"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_string",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_column",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "data = [(\"03-29-2025\",),\n",
    "        (\"06-15-2024\",),\n",
    "        (\"09-25-2023\",),\n",
    "        (\"02-10-2022\",),\n",
    "        (\"04-22-2024\",),\n",
    "        (\"07-03-2021\",)]\n",
    "\n",
    "df_na = spark.createDataFrame(data, [\"date_string\"])\n",
    "\n",
    "# Convert to DateType\n",
    "df_na_dt = df_na.withColumn(\"date_column\", to_date(col(\"date_string\"), \"MM-dd-yyyy\").cast(DateType()))\n",
    "display(df_na_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f08eeae-ddfd-4d16-8fe6-3385295ab9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**d) Using a \"Literal\" and Casting to \"DateType\"**\n",
    "- You can also use a **literal** value and **cast** it directly to a **DateType**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2200b6-6855-49d1-84c6-9db32f252a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_val</th></tr></thead><tbody><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr><tr><td>2025-03-29</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ],
        [
         "2025-03-29"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_val",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a literal timestamp string and cast it to DateType\n",
    "df_literal = spark.range(8)\\\n",
    "    .select(F.lit(\"2025-03-29 14:30:45\").cast(DateType()).alias(\"date_val\"))\n",
    "display(df_literal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1df81205-c40d-4cfa-8835-0fc19ab60619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Takeaways**\n",
    "- Direct Cast **(.cast(DateType()))** works when the column is already in **yyyy-MM-dd or TimestampType**.\n",
    "- For **custom formats**, use **to_date()** before **casting**.\n",
    "- **Time** information is **removed** when **casting** from **TimestampType to DateType**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d503f1a3-7ef1-4379-95b4-9a4dabc84edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3) .cast(\"date\")\n",
    "\n",
    "- In Spark, **.cast(\"date\")** is a **shorthand** way to **cast** a column to **DateType**.\n",
    "- It is commonly used when working with **string timestamps** that need to be converted into **DateType**.\n",
    "- Works directly on **yyyy-MM-dd** formatted **strings** but may require **to_date()** for **other formats**.\n",
    "- **Removes** the **time** portion from **TimestampType**, keeping **only the date**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78d4792d-2d4b-489a-a553-f738806384fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Features:**\n",
    "\n",
    "✅ Identical to **.cast(DateType())**, but uses a string notation.\n",
    "\n",
    "✅ Converts **string or timestamp** to **date**, assuming **\"yyyy-MM-dd\"** format.\n",
    "\n",
    "✅ **Cannot** handle **different formats** like **to_date()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "571e1633-2bec-49c5-b11e-09590c65fd42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "| col_name\t  | After col_name.cast(\"date\")  |\n",
    "|-------------|------------------------------|\n",
    "| \"2024-03-06\"\t | 2024-03-06 (Date)  |\n",
    "| \"06-03-2024\"\t | NULL (Format mismatch)  |\n",
    "| \"2024-03-06 12:30:00\"\t | 2024-03-06 (Time removed) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63fc92c2-989d-4b08-8fc5-c8b2b50728a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**a) Casting a \"String\" Column to \"DateType\"**\n",
    "\n",
    "- If a column contains **date strings** in the format **yyyy-MM-dd**, you can directly **cast** it to **DateType**.\n",
    "- You can **cast** a **string to DateType** directly using **.cast(\"date\")**.\n",
    "- The input **string** should be in a **recognizable date format**, usually **yyyy-MM-dd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54c3a41-171c-4f0c-8831-e06154f44e2e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "convert string column to DateType"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_str</th><th>date_col</th></tr></thead><tbody><tr><td>2023-12-25</td><td>2023-12-25</td></tr><tr><td>2024-01-01</td><td>2024-01-01</td></tr><tr><td>2020-03-11</td><td>2020-03-11</td></tr><tr><td>2021-04-21</td><td>2021-04-21</td></tr><tr><td>2022-06-09</td><td>2022-06-09</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-12-25",
         "2023-12-25"
        ],
        [
         "2024-01-01",
         "2024-01-01"
        ],
        [
         "2020-03-11",
         "2020-03-11"
        ],
        [
         "2021-04-21",
         "2021-04-21"
        ],
        [
         "2022-06-09",
         "2022-06-09"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create DataFrame with date strings\n",
    "df_cast = spark.createDataFrame([(\"2023-12-25\",),\n",
    "                                 (\"2024-01-01\",),\n",
    "                                 (\"2020-03-11\",),\n",
    "                                 (\"2021-04-21\",),\n",
    "                                 (\"2022-06-09\",)],\n",
    "                                [\"date_str\"])\n",
    "\n",
    "# Cast string column to DateType\n",
    "df_cast_dt = df_cast.withColumn(\"date_col\", col(\"date_str\").cast(\"date\"))\n",
    "display(df_cast_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48e0bcf8-f0d2-43e2-b3e5-84429e7ee454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**b) Casting a \"Timestamp\" Column to \"DateType\"**\n",
    "\n",
    "- If you have a **TimestampType** column and want to extract only the **date** part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "976c0c89-df63-478e-988b-0ad83d08d105",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"timestamp_col\":198},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756194936764}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "convert timestamp column to DateType, removing time part."
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>timestamp_col</th><th>date_col</th></tr></thead><tbody><tr><td>1</td><td>2025-08-26T07:55:31.813Z</td><td>2025-08-26</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "2025-08-26T07:55:31.813Z",
         "2025-08-26"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp_col",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# Create DataFrame with current timestamp\n",
    "df_ts_dt = spark.createDataFrame([(1,)], [\"id\"])\n",
    "\n",
    "df_ts_dt_ts = df_ts_dt.withColumn(\"timestamp_col\", current_timestamp())\n",
    "\n",
    "# Cast TimestampType to DateType\n",
    "df_ts_dt_ts_final = df_ts_dt_ts.withColumn(\"date_col\", col(\"timestamp_col\").cast(\"date\"))\n",
    "display(df_ts_dt_ts_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dba704b-1cf3-4477-a95d-63170dbe075b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"current_ts\":204},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756194956289}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>current_ts</th><th>date_col</th></tr></thead><tbody><tr><td>0</td><td>2025-08-26T07:55:51.267Z</td><td>2025-08-26</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "2025-08-26T07:55:51.267Z",
         "2025-08-26"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "current_ts",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# Create a DataFrame with the current timestamp\n",
    "df_ts_cts = spark.range(1)\\\n",
    "  .withColumn(\"current_ts\", current_timestamp())\n",
    "\n",
    "# Casting the timestamp column to date\n",
    "df_ts_with_date = df_ts_cts.withColumn(\"date_col\", col(\"current_ts\").cast(\"date\"))\n",
    "display(df_ts_with_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ea4416-7c0a-4b52-8daf-ca741727c122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**c) Casting a \"String\" Column with \"Custom Format\"**\n",
    "\n",
    "- If the **date string** is in a **non-default** format, first use **to_date()** before **casting**.\n",
    "\n",
    "- If you have a **string** in a **custom format (MM-dd-yyyy)**, and you want to **cast** it to **DateType**, you first need to **convert** the **string into a TimestampType or DateType** using functions like **to_date()**. Once the **string** is in the **correct format**, you can use **.cast(\"date\")**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbbf4c42-1704-45af-8db9-26a673a22383",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "input format is MM-dd-yyyy, to_date() is used before casting"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_str</th><th>date_col</th></tr></thead><tbody><tr><td>06-24-2019</td><td>2019-06-24</td></tr><tr><td>03-14-2020</td><td>2020-03-14</td></tr><tr><td>05-12-2021</td><td>2021-05-12</td></tr><tr><td>07-17-2022</td><td>2022-07-17</td></tr><tr><td>08-04-2023</td><td>2023-08-04</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "06-24-2019",
         "2019-06-24"
        ],
        [
         "03-14-2020",
         "2020-03-14"
        ],
        [
         "05-12-2021",
         "2021-05-12"
        ],
        [
         "07-17-2022",
         "2022-07-17"
        ],
        [
         "08-04-2023",
         "2023-08-04"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Create DataFrame with custom date format\n",
    "df_cust_date1 = spark.createDataFrame([(\"06-24-2019\",),\n",
    "                                       (\"03-14-2020\",),\n",
    "                                       (\"05-12-2021\",),\n",
    "                                       (\"07-17-2022\",),\n",
    "                                       (\"08-04-2023\",)], [\"date_str\"])\n",
    "\n",
    "# Convert to DateType using to_date() and then cast (optional)\n",
    "df_cust_date1_cast = df_cust_date1\\\n",
    "  .withColumn(\"date_col\", to_date(col(\"date_str\"), \"MM-dd-yyyy\").cast(\"date\"))\n",
    "  \n",
    "display(df_cust_date1_cast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a1fdaea-d127-411b-97cd-7ab9189f2deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**d) Casting a Column from Integer to Date**\n",
    "\n",
    "- If you have an **integer** representing a **date**, such as **20210625**, and you want to **convert** it to a **DateType**, you can first convert the **integer to a string** and then **cast** it to **DateType**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea4cf31f-69ea-4d57-956c-b11d52b0cf22",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756195162304}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "convert \"integer\" to \"date\""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_int</th><th>date_col</th></tr></thead><tbody><tr><td>20210625</td><td>2021-06-25</td></tr><tr><td>20230710</td><td>2023-07-10</td></tr><tr><td>20210415</td><td>2021-04-15</td></tr><tr><td>20220318</td><td>2022-03-18</td></tr><tr><td>20250928</td><td>2025-09-28</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         20210625,
         "2021-06-25"
        ],
        [
         20230710,
         "2023-07-10"
        ],
        [
         20210415,
         "2021-04-15"
        ],
        [
         20220318,
         "2022-03-18"
        ],
        [
         20250928,
         "2025-09-28"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_int",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Sample DataFrame with date as integer\n",
    "df_expr = spark.createDataFrame([(20210625,),\n",
    "                                 (20230710,),\n",
    "                                 (20210415,),\n",
    "                                 (20220318,),\n",
    "                                 (20250928,),], ['date_int'])\n",
    "\n",
    "# Convert integer to string -> Reformat to yyyy-MM-dd -> Cast to DateType\n",
    "df_expr_dt = df_expr\\\n",
    "  .withColumn(\"date_col\", expr(\"to_date(cast(date_int as string), 'yyyyMMdd')\"))\n",
    "\n",
    "display(df_expr_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "868bc3ee-861c-4a75-96e4-b06e05b75ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**e) Using .cast(\"date\") with a Column of Dates**\n",
    "\n",
    "- If you have a DataFrame with **dates** already in **string** format but need to explicitly **cast** them to **DateType**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215514d1-0998-4e3c-8cad-5438adf85c99",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "convert \"date string\" to \"date\""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_str</th><th>date_col</th></tr></thead><tbody><tr><td>2021-01-01</td><td>2021-01-01</td></tr><tr><td>2022-02-14</td><td>2022-02-14</td></tr><tr><td>2023-04-21</td><td>2023-04-21</td></tr><tr><td>2025-06-21</td><td>2025-06-21</td></tr><tr><td>2025-09-19</td><td>2025-09-19</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2021-01-01",
         "2021-01-01"
        ],
        [
         "2022-02-14",
         "2022-02-14"
        ],
        [
         "2023-04-21",
         "2023-04-21"
        ],
        [
         "2025-06-21",
         "2025-06-21"
        ],
        [
         "2025-09-19",
         "2025-09-19"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample DataFrame with string dates\n",
    "df_dt_str = spark.createDataFrame([('2021-01-01',),\n",
    "                                   ('2022-02-14',),\n",
    "                                   ('2023-04-21',),\n",
    "                                   ('2025-06-21',),\n",
    "                                   ('2025-09-19',)], ['date_str'])\n",
    "\n",
    "# Cast string column to DateType\n",
    "df_dt_str_type = df_dt_str.withColumn('date_col', col('date_str').cast(\"date\"))\n",
    "display(df_dt_str_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cef5d0b-7f8f-4061-bd66-f687d56bcf44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**f) Using .cast(\"date\") in SQL Expressions**\n",
    "\n",
    "- You can also use **.cast(\"date\")** within **selectExpr()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4c6fdea-a1b9-4914-85b5-7c2e8c8d8585",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"original\":141},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756195468557}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "\"Timestamp string\" has been converted to \"DateType\", keeping only \"YYYY-MM-DD\""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>original</th><th>date_col</th></tr></thead><tbody><tr><td>2024-07-15 10:30:00</td><td>2024-07-15</td></tr><tr><td>2025-09-25 20:55:55</td><td>2025-09-25</td></tr><tr><td>2023-10-19 13:43:23</td><td>2023-10-19</td></tr><tr><td>2022-12-29 23:59:19</td><td>2022-12-29</td></tr><tr><td>2021-04-12 19:51:27</td><td>2021-04-12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2024-07-15 10:30:00",
         "2024-07-15"
        ],
        [
         "2025-09-25 20:55:55",
         "2025-09-25"
        ],
        [
         "2023-10-19 13:43:23",
         "2023-10-19"
        ],
        [
         "2022-12-29 23:59:19",
         "2022-12-29"
        ],
        [
         "2021-04-12 19:51:27",
         "2021-04-12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "original",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_selectexp = spark.createDataFrame([(\"2024-07-15 10:30:00\",),\n",
    "                                      (\"2025-09-25 20:55:55\",),\n",
    "                                      (\"2023-10-19 13:43:23\",),\n",
    "                                      (\"2022-12-29 23:59:19\",),\n",
    "                                      (\"2021-04-12 19:51:27\",)], [\"timestamp_str\"])\n",
    "\n",
    "# Using selectExpr to cast column\n",
    "df_selectexp_cast = df_selectexp.selectExpr(\"timestamp_str as original\", \"cast(timestamp_str as date) as date_col\")\n",
    "display(df_selectexp_cast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9411f5e-f22b-4b49-8b48-53fcb6545d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Difference between \".cast(DateType())\" and \".cast(\"date\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eda9a9d-be78-4932-8107-ea0162944d29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Differences at a Glance**\n",
    "\n",
    "| Feature\t   | .cast(DateType())\t | .cast(\"date\") |\n",
    "|------------|---------------------|---------------|\n",
    "| Explicit Import?\t| Yes (**from pyspark.sql.types import DateType**)\t| **No** |\n",
    "| Data Type Usage? | Uses PySpark **DateType()** object\t| Uses string **\"date\"** |\n",
    "| Readability?\t| More explicit |\tMore concise |\n",
    "| Error Handling?\t| **fails if input format is incorrect**\t| Same behavior |\n",
    "| Use Case?\t| **Schema definition**, strict typing |\t**Quick conversions** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ff9ecee-f474-4179-a4a3-8c9f823fe89a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**a) \".cast(DateType())\" (Using PySpark DataType)**\n",
    "\n",
    "- Explicitly uses the **DateType** from **pyspark.sql.types**.\n",
    "\n",
    "- Requires **importing DateType** from **pyspark.sql.types**.\n",
    "\n",
    "- Used when **defining schema** or explicitly specifying the **data type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31b9ee22-45d8-4aad-b125-28b7784e73c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_str</th><th>date_col</th></tr></thead><tbody><tr><td>2023-06-15</td><td>2023-06-15</td></tr><tr><td>2024-03-25</td><td>2024-03-25</td></tr><tr><td>2023-07-19</td><td>2023-07-19</td></tr><tr><td>2023-11-15</td><td>2023-11-15</td></tr><tr><td>2022-04-09</td><td>2022-04-09</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-06-15",
         "2023-06-15"
        ],
        [
         "2024-03-25",
         "2024-03-25"
        ],
        [
         "2023-07-19",
         "2023-07-19"
        ],
        [
         "2023-11-15",
         "2023-11-15"
        ],
        [
         "2022-04-09",
         "2022-04-09"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.createDataFrame([('2023-06-15',),\n",
    "                            ('2024-03-25',),\n",
    "                            ('2023-07-19',),\n",
    "                            ('2023-11-15',),\n",
    "                            ('2022-04-09',)], ['date_str'])\n",
    "\n",
    "# Using DateType()\n",
    "df = df.withColumn(\"date_col\", col(\"date_str\").cast(DateType()))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a06df89e-bf9d-4ed1-8dd3-dc5142a69550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**b) \".cast(\"date\")\" (Using String Representation)**\n",
    "\n",
    "- Uses the **string \"date\"** as an **alias** for **DateType**.\n",
    "\n",
    "- **No** need to **import DateType**.\n",
    "\n",
    "- Internally, **Spark converts \"date\" to DateType()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87804e03-1efd-43d8-aa99-15762ad95b43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date_str</th><th>date_col</th></tr></thead><tbody><tr><td>2021-02-25</td><td>2021-02-25</td></tr><tr><td>2023-06-12</td><td>2023-06-12</td></tr><tr><td>2025-04-14</td><td>2025-04-14</td></tr><tr><td>2024-09-19</td><td>2024-09-19</td></tr><tr><td>2020-08-17</td><td>2020-08-17</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2021-02-25",
         "2021-02-25"
        ],
        [
         "2023-06-12",
         "2023-06-12"
        ],
        [
         "2025-04-14",
         "2025-04-14"
        ],
        [
         "2024-09-19",
         "2024-09-19"
        ],
        [
         "2020-08-17",
         "2020-08-17"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date_str",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date_col",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.createDataFrame([('2021-02-25',),\n",
    "                            ('2023-06-12',),\n",
    "                            ('2025-04-14',),\n",
    "                            ('2024-09-19',),\n",
    "                            ('2020-08-17',)], ['date_str'])\n",
    "\n",
    "# Using \"date\"\n",
    "df = df.withColumn(\"date_col\", col(\"date_str\").cast(\"date\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1e558b0-ca3d-4633-bfcb-9fcd412eac46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Difference between \"to_date()\", \".cast(DateType())\" and \".cast(\"date\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9b3e295-f5e4-4b07-92ec-3d9dd62def5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Differences:**\n",
    "\n",
    "| Feature\t | to_date()\t | .cast(DateType()) / .cast(\"date\") |\n",
    "|----------|-------------|--------------------------|\n",
    "| Purpose\t | Converts **string to date** using a **specific format**\t | Converts to **date** assuming **\"yyyy-MM-dd\"** |\n",
    "| Format  | Handling\tSupports **custom formats (yyMMdd, dd-MM-yyyy)**\t| Works only for **\"yyyy-MM-dd\"** |\n",
    "| Time Removal\t| **Removes time part**\t| **Removes time part** |\n",
    "| Error Handling\t| Returns **NULL** if **format doesn't match**\t| Returns **NULL** if **format doesn't match** |\n",
    "| Recommended Use\t| When working with **various date formats**\t| When the **format** is already **\"yyyy-MM-dd\"** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8923121b-3ee8-47ea-bb60-9c2c2234b8ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Best Practices\n",
    "\n",
    "- Use **to_date(col, format)** if your **date format varies**.\n",
    "\n",
    "- Use **.cast(DateType()) or .cast(\"date\")** if the column is already in **\"yyyy-MM-dd\"** format.\n",
    "\n",
    "- Avoid **.cast()** if your column has **different formats**, use **to_date()** instead."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "94_difference bn to_date(), .cast(DateType()) and .cast(_date_)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}