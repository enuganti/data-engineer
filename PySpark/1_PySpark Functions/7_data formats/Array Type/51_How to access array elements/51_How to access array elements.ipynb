{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e652852-ab5d-4c00-8004-4070eea992b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**How to transform String Columns to ArrayType column and flatten into individual columns?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b86c113-55fd-41e9-962b-104125036bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     index\n",
    "     getItem\n",
    "     element_at\n",
    "     Array Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "550e2afe-e099-4df8-bc27-5712f8464456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, lit, array, array_contains, size, element_at\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3ab5a94-baf2-4005-867e-6f4a57a850f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "create dataframe"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- FullName: string (nullable = true)\n |-- LearntLanguages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- ToLearnLanguages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- Rating: array (nullable = true)\n |    |-- element: integer (containsNull = true)\n |-- PresentState: string (nullable = true)\n |-- PreviousState: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Experience: integer (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FullName</th><th>LearntLanguages</th><th>ToLearnLanguages</th><th>Rating</th><th>PresentState</th><th>PreviousState</th><th>Age</th><th>Experience</th></tr></thead><tbody><tr><td>Amar,,Singh</td><td>List(Java, Scala, C++)</td><td>List(Spark, Java, Azure Databricks)</td><td>List(8, 9, 5, 7)</td><td>Bangalore</td><td>Chennai</td><td>25</td><td>7</td></tr><tr><td>Ramesh,Rathode,</td><td>List(Python, PySpark, C)</td><td>List(spark sql, ADF)</td><td>List(11, 3, 6, 8)</td><td>Hyderabad</td><td>Kochin</td><td>35</td><td>8</td></tr><tr><td>Asha,,Rani</td><td>List(Devops, VB, Git)</td><td>List(ApacheSpark, Python)</td><td>List(5, 6, 8, 10)</td><td>Amaravathi</td><td>Noida</td><td>30</td><td>10</td></tr><tr><td>Rakesh,Kothur,</td><td>List(SQL, Azure, AWS)</td><td>List(PySpark, Oracle, Confluence)</td><td>List(12, 6, 8, 15)</td><td>Noida</td><td>Mumbai</td><td>33</td><td>5</td></tr><tr><td>Krishna,,Joshi</td><td>List(GCC, Visual Studio)</td><td>List(SQL, Databricks, SQL Editor)</td><td>List(2, 6, 5, 8)</td><td>Delhi</td><td>Kolkata</td><td>28</td><td>6</td></tr><tr><td>Hari,,Rani</td><td>List(Devops, VB, Git)</td><td>List(ApacheSpark, Python)</td><td>List(5, 6, 8, 10)</td><td>Amaravathi</td><td>Noida</td><td>30</td><td>10</td></tr><tr><td>Rakesh,kumar,</td><td>List(SQL, Azure, AWS)</td><td>List(PySpark, Oracle, Schema)</td><td>List(12, 6, 8, 15)</td><td>luknow</td><td>Mumbai</td><td>33</td><td>5</td></tr><tr><td>karan,,Joshi</td><td>List(AWS, Visual Studio)</td><td>List(SQL, Git, SQL Editor)</td><td>List(2, 6, 5, 8)</td><td>Delhi</td><td>Noida</td><td>28</td><td>6</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Amar,,Singh",
         [
          "Java",
          "Scala",
          "C++"
         ],
         [
          "Spark",
          "Java",
          "Azure Databricks"
         ],
         [
          8,
          9,
          5,
          7
         ],
         "Bangalore",
         "Chennai",
         25,
         7
        ],
        [
         "Ramesh,Rathode,",
         [
          "Python",
          "PySpark",
          "C"
         ],
         [
          "spark sql",
          "ADF"
         ],
         [
          11,
          3,
          6,
          8
         ],
         "Hyderabad",
         "Kochin",
         35,
         8
        ],
        [
         "Asha,,Rani",
         [
          "Devops",
          "VB",
          "Git"
         ],
         [
          "ApacheSpark",
          "Python"
         ],
         [
          5,
          6,
          8,
          10
         ],
         "Amaravathi",
         "Noida",
         30,
         10
        ],
        [
         "Rakesh,Kothur,",
         [
          "SQL",
          "Azure",
          "AWS"
         ],
         [
          "PySpark",
          "Oracle",
          "Confluence"
         ],
         [
          12,
          6,
          8,
          15
         ],
         "Noida",
         "Mumbai",
         33,
         5
        ],
        [
         "Krishna,,Joshi",
         [
          "GCC",
          "Visual Studio"
         ],
         [
          "SQL",
          "Databricks",
          "SQL Editor"
         ],
         [
          2,
          6,
          5,
          8
         ],
         "Delhi",
         "Kolkata",
         28,
         6
        ],
        [
         "Hari,,Rani",
         [
          "Devops",
          "VB",
          "Git"
         ],
         [
          "ApacheSpark",
          "Python"
         ],
         [
          5,
          6,
          8,
          10
         ],
         "Amaravathi",
         "Noida",
         30,
         10
        ],
        [
         "Rakesh,kumar,",
         [
          "SQL",
          "Azure",
          "AWS"
         ],
         [
          "PySpark",
          "Oracle",
          "Schema"
         ],
         [
          12,
          6,
          8,
          15
         ],
         "luknow",
         "Mumbai",
         33,
         5
        ],
        [
         "karan,,Joshi",
         [
          "AWS",
          "Visual Studio"
         ],
         [
          "SQL",
          "Git",
          "SQL Editor"
         ],
         [
          2,
          6,
          5,
          8
         ],
         "Delhi",
         "Noida",
         28,
         6
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "FullName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LearntLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "ToLearnLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Rating",
         "type": "{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "PresentState",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "PreviousState",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Experience",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(\"Amar,,Singh\",[\"Java\",\"Scala\",\"C++\"], [\"Spark\",\"Java\",\"Azure Databricks\"], [8, 9, 5, 7], \"Bangalore\", \"Chennai\", 25, 7),\n",
    "        (\"Ramesh,Rathode,\", [\"Python\",\"PySpark\",\"C\"], [\"spark sql\",\"ADF\"], [11, 3, 6, 8], \"Hyderabad\", \"Kochin\", 35, 8),\n",
    "        (\"Asha,,Rani\", [\"Devops\",\"VB\",\"Git\"], [\"ApacheSpark\",\"Python\"], [5, 6, 8, 10], \"Amaravathi\", \"Noida\", 30, 10),\n",
    "        (\"Rakesh,Kothur,\", [\"SQL\",\"Azure\",\"AWS\"], [\"PySpark\",\"Oracle\",\"Confluence\"], [12, 6, 8, 15], \"Noida\", \"Mumbai\", 33, 5),\n",
    "        (\"Krishna,,Joshi\", [\"GCC\",\"Visual Studio\"], [\"SQL\",\"Databricks\",\"SQL Editor\"], [2, 6, 5, 8], \"Delhi\", \"Kolkata\", 28, 6),\n",
    "        (\"Hari,,Rani\", [\"Devops\",\"VB\",\"Git\"], [\"ApacheSpark\",\"Python\"], [5, 6, 8, 10], \"Amaravathi\", \"Noida\", 30, 10),\n",
    "        (\"Rakesh,kumar,\", [\"SQL\",\"Azure\",\"AWS\"], [\"PySpark\",\"Oracle\",\"Schema\"], [12, 6, 8, 15], \"luknow\", \"Mumbai\", 33, 5),\n",
    "        (\"karan,,Joshi\", [\"AWS\",\"Visual Studio\"], [\"SQL\",\"Git\",\"SQL Editor\"], [2, 6, 5, 8], \"Delhi\", \"Noida\", 28, 6),\n",
    "        ]\n",
    "\n",
    "schema = StructType([ \n",
    "    StructField(\"FullName\", StringType(), True), \n",
    "    StructField(\"LearntLanguages\", ArrayType(StringType()), True), \n",
    "    StructField(\"ToLearnLanguages\", ArrayType(StringType()), True),\n",
    "    StructField(\"Rating\", ArrayType(IntegerType()), True), \n",
    "    StructField(\"PresentState\", StringType(), True), \n",
    "    StructField(\"PreviousState\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Experience\", IntegerType(), True)\n",
    "  ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=data, schema=schema)\n",
    "df2.printSchema()\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89525225-aeb8-4875-81df-68b4bad16cc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The below example **combines** the data from **PresentState and PreviousState** and creates a **new column states**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82271418-3823-43f8-91c4-0cd748895bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FullName</th><th>States</th><th>Size</th></tr></thead><tbody><tr><td>Amar,,Singh</td><td>List(Bangalore, Chennai)</td><td>2</td></tr><tr><td>Ramesh,Rathode,</td><td>List(Hyderabad, Kochin)</td><td>2</td></tr><tr><td>Asha,,Rani</td><td>List(Amaravathi, Noida)</td><td>2</td></tr><tr><td>Rakesh,Kothur,</td><td>List(Noida, Mumbai)</td><td>2</td></tr><tr><td>Krishna,,Joshi</td><td>List(Delhi, Kolkata)</td><td>2</td></tr><tr><td>Hari,,Rani</td><td>List(Amaravathi, Noida)</td><td>2</td></tr><tr><td>Rakesh,kumar,</td><td>List(luknow, Mumbai)</td><td>2</td></tr><tr><td>karan,,Joshi</td><td>List(Delhi, Noida)</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Amar,,Singh",
         [
          "Bangalore",
          "Chennai"
         ],
         2
        ],
        [
         "Ramesh,Rathode,",
         [
          "Hyderabad",
          "Kochin"
         ],
         2
        ],
        [
         "Asha,,Rani",
         [
          "Amaravathi",
          "Noida"
         ],
         2
        ],
        [
         "Rakesh,Kothur,",
         [
          "Noida",
          "Mumbai"
         ],
         2
        ],
        [
         "Krishna,,Joshi",
         [
          "Delhi",
          "Kolkata"
         ],
         2
        ],
        [
         "Hari,,Rani",
         [
          "Amaravathi",
          "Noida"
         ],
         2
        ],
        [
         "Rakesh,kumar,",
         [
          "luknow",
          "Mumbai"
         ],
         2
        ],
        [
         "karan,,Joshi",
         [
          "Delhi",
          "Noida"
         ],
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "FullName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "States",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Size",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.select(df2.FullName, array(df2.PresentState, df2.PreviousState).alias(\"States\"))\\\n",
    "   .withColumn(\"Size\", F.size(\"States\")).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "013da891-cd1e-4c66-95cf-ceb61b3a0a48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7417f007-93d3-4a91-b23d-9da8064675f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FullName</th><th>Rating</th><th>Rating1</th><th>Rating2</th><th>Rating3</th><th>Rating4</th></tr></thead><tbody><tr><td>Amar,,Singh</td><td>List(8, 9, 5, 7)</td><td>8</td><td>9</td><td>5</td><td>7</td></tr><tr><td>Ramesh,Rathode,</td><td>List(11, 3, 6, 8)</td><td>11</td><td>3</td><td>6</td><td>8</td></tr><tr><td>Asha,,Rani</td><td>List(5, 6, 8, 10)</td><td>5</td><td>6</td><td>8</td><td>10</td></tr><tr><td>Rakesh,Kothur,</td><td>List(12, 6, 8, 15)</td><td>12</td><td>6</td><td>8</td><td>15</td></tr><tr><td>Krishna,,Joshi</td><td>List(2, 6, 5, 8)</td><td>2</td><td>6</td><td>5</td><td>8</td></tr><tr><td>Hari,,Rani</td><td>List(5, 6, 8, 10)</td><td>5</td><td>6</td><td>8</td><td>10</td></tr><tr><td>Rakesh,kumar,</td><td>List(12, 6, 8, 15)</td><td>12</td><td>6</td><td>8</td><td>15</td></tr><tr><td>karan,,Joshi</td><td>List(2, 6, 5, 8)</td><td>2</td><td>6</td><td>5</td><td>8</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Amar,,Singh",
         [
          8,
          9,
          5,
          7
         ],
         8,
         9,
         5,
         7
        ],
        [
         "Ramesh,Rathode,",
         [
          11,
          3,
          6,
          8
         ],
         11,
         3,
         6,
         8
        ],
        [
         "Asha,,Rani",
         [
          5,
          6,
          8,
          10
         ],
         5,
         6,
         8,
         10
        ],
        [
         "Rakesh,Kothur,",
         [
          12,
          6,
          8,
          15
         ],
         12,
         6,
         8,
         15
        ],
        [
         "Krishna,,Joshi",
         [
          2,
          6,
          5,
          8
         ],
         2,
         6,
         5,
         8
        ],
        [
         "Hari,,Rani",
         [
          5,
          6,
          8,
          10
         ],
         5,
         6,
         8,
         10
        ],
        [
         "Rakesh,kumar,",
         [
          12,
          6,
          8,
          15
         ],
         12,
         6,
         8,
         15
        ],
        [
         "karan,,Joshi",
         [
          2,
          6,
          5,
          8
         ],
         2,
         6,
         5,
         8
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "FullName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Rating",
         "type": "{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Rating1",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Rating2",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Rating3",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Rating4",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.withColumn(\"Rating1\", df2[\"Rating\"][0])\\\n",
    "   .withColumn(\"Rating2\", df2[\"Rating\"][1])\\\n",
    "   .withColumn(\"Rating3\", df2[\"Rating\"][2])\\\n",
    "   .withColumn(\"Rating4\", df2[\"Rating\"][3])\\\n",
    "   .select(\"FullName\", \"Rating\", \"Rating1\", \"Rating2\", \"Rating3\", \"Rating4\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d8414e9-e58d-426a-8d70-800baac0bdda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **getItem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d35e29f-5d1b-4880-b488-f6388182c118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ToLearnLanguages</th><th>get_TLL_01</th><th>get_TLL_02</th><th>get_TLL_03</th></tr></thead><tbody><tr><td>List(Spark, Java, Azure Databricks)</td><td>Spark</td><td>Java</td><td>Azure Databricks</td></tr><tr><td>List(spark sql, ADF)</td><td>spark sql</td><td>ADF</td><td>null</td></tr><tr><td>List(ApacheSpark, Python)</td><td>ApacheSpark</td><td>Python</td><td>null</td></tr><tr><td>List(PySpark, Oracle, Confluence)</td><td>PySpark</td><td>Oracle</td><td>Confluence</td></tr><tr><td>List(SQL, Databricks, SQL Editor)</td><td>SQL</td><td>Databricks</td><td>SQL Editor</td></tr><tr><td>List(ApacheSpark, Python)</td><td>ApacheSpark</td><td>Python</td><td>null</td></tr><tr><td>List(PySpark, Oracle, Schema)</td><td>PySpark</td><td>Oracle</td><td>Schema</td></tr><tr><td>List(SQL, Git, SQL Editor)</td><td>SQL</td><td>Git</td><td>SQL Editor</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "Spark",
          "Java",
          "Azure Databricks"
         ],
         "Spark",
         "Java",
         "Azure Databricks"
        ],
        [
         [
          "spark sql",
          "ADF"
         ],
         "spark sql",
         "ADF",
         null
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "ApacheSpark",
         "Python",
         null
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Confluence"
         ],
         "PySpark",
         "Oracle",
         "Confluence"
        ],
        [
         [
          "SQL",
          "Databricks",
          "SQL Editor"
         ],
         "SQL",
         "Databricks",
         "SQL Editor"
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "ApacheSpark",
         "Python",
         null
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Schema"
         ],
         "PySpark",
         "Oracle",
         "Schema"
        ],
        [
         [
          "SQL",
          "Git",
          "SQL Editor"
         ],
         "SQL",
         "Git",
         "SQL Editor"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ToLearnLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "get_TLL_01",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "get_TLL_02",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "get_TLL_03",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.withColumn(\"get_TLL_01\", col(\"ToLearnLanguages\").getItem(0))\\\n",
    "           .withColumn(\"get_TLL_02\", col(\"ToLearnLanguages\").getItem(1))\\\n",
    "           .withColumn(\"get_TLL_03\", col(\"ToLearnLanguages\").getItem(2))\\\n",
    "           .select(\"ToLearnLanguages\", \"get_TLL_01\", \"get_TLL_02\", \"get_TLL_03\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38d67575-7e90-41e5-8607-f710095bdfda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **element_at**\n",
    "\n",
    "- The **position is not zero** based, but **1 based index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d2f5cf5-028b-4a8c-ae3e-8fcea94c5b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ToLearnLanguages</th><th>elm_TLL_01</th><th>elm_TLL_02</th><th>elm_TLL_03</th><th>elm_TLL_04</th></tr></thead><tbody><tr><td>List(Spark, Java, Azure Databricks)</td><td>Spark</td><td>Java</td><td>Azure Databricks</td><td>Azure Databricks</td></tr><tr><td>List(spark sql, ADF)</td><td>spark sql</td><td>ADF</td><td>null</td><td>ADF</td></tr><tr><td>List(ApacheSpark, Python)</td><td>ApacheSpark</td><td>Python</td><td>null</td><td>Python</td></tr><tr><td>List(PySpark, Oracle, Confluence)</td><td>PySpark</td><td>Oracle</td><td>Confluence</td><td>Confluence</td></tr><tr><td>List(SQL, Databricks, SQL Editor)</td><td>SQL</td><td>Databricks</td><td>SQL Editor</td><td>SQL Editor</td></tr><tr><td>List(ApacheSpark, Python)</td><td>ApacheSpark</td><td>Python</td><td>null</td><td>Python</td></tr><tr><td>List(PySpark, Oracle, Schema)</td><td>PySpark</td><td>Oracle</td><td>Schema</td><td>Schema</td></tr><tr><td>List(SQL, Git, SQL Editor)</td><td>SQL</td><td>Git</td><td>SQL Editor</td><td>SQL Editor</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "Spark",
          "Java",
          "Azure Databricks"
         ],
         "Spark",
         "Java",
         "Azure Databricks",
         "Azure Databricks"
        ],
        [
         [
          "spark sql",
          "ADF"
         ],
         "spark sql",
         "ADF",
         null,
         "ADF"
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "ApacheSpark",
         "Python",
         null,
         "Python"
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Confluence"
         ],
         "PySpark",
         "Oracle",
         "Confluence",
         "Confluence"
        ],
        [
         [
          "SQL",
          "Databricks",
          "SQL Editor"
         ],
         "SQL",
         "Databricks",
         "SQL Editor",
         "SQL Editor"
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "ApacheSpark",
         "Python",
         null,
         "Python"
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Schema"
         ],
         "PySpark",
         "Oracle",
         "Schema",
         "Schema"
        ],
        [
         [
          "SQL",
          "Git",
          "SQL Editor"
         ],
         "SQL",
         "Git",
         "SQL Editor",
         "SQL Editor"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ToLearnLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "elm_TLL_01",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "elm_TLL_02",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "elm_TLL_03",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "elm_TLL_04",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.withColumn(\"elm_TLL_01\", element_at(\"ToLearnLanguages\", 1))\\\n",
    "           .withColumn(\"elm_TLL_02\", element_at(\"ToLearnLanguages\", 2))\\\n",
    "           .withColumn(\"elm_TLL_03\", element_at(\"ToLearnLanguages\", 3))\\\n",
    "           .withColumn(\"elm_TLL_04\", element_at(\"ToLearnLanguages\", -1))\\\n",
    "           .select(\"ToLearnLanguages\", \"elm_TLL_01\", \"elm_TLL_02\", \"elm_TLL_03\", \"elm_TLL_04\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "170c0d71-0ab0-4143-9ea5-17fd3da1ce41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ToLearnLanguages</th><th>lit</th></tr></thead><tbody><tr><td>List(Spark, Java, Azure Databricks)</td><td>Java</td></tr><tr><td>List(spark sql, ADF)</td><td>ADF</td></tr><tr><td>List(ApacheSpark, Python)</td><td>Python</td></tr><tr><td>List(PySpark, Oracle, Confluence)</td><td>Oracle</td></tr><tr><td>List(SQL, Databricks, SQL Editor)</td><td>Databricks</td></tr><tr><td>List(ApacheSpark, Python)</td><td>Python</td></tr><tr><td>List(PySpark, Oracle, Schema)</td><td>Oracle</td></tr><tr><td>List(SQL, Git, SQL Editor)</td><td>Git</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "Spark",
          "Java",
          "Azure Databricks"
         ],
         "Java"
        ],
        [
         [
          "spark sql",
          "ADF"
         ],
         "ADF"
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "Python"
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Confluence"
         ],
         "Oracle"
        ],
        [
         [
          "SQL",
          "Databricks",
          "SQL Editor"
         ],
         "Databricks"
        ],
        [
         [
          "ApacheSpark",
          "Python"
         ],
         "Python"
        ],
        [
         [
          "PySpark",
          "Oracle",
          "Schema"
         ],
         "Oracle"
        ],
        [
         [
          "SQL",
          "Git",
          "SQL Editor"
         ],
         "Git"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ToLearnLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "lit",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.withColumn(\"lit\", element_at(\"ToLearnLanguages\", lit(2)))\\\n",
    "           .select(\"ToLearnLanguages\", \"lit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd814723-1a9a-40fb-8993-e6973e99ae57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **Array Size**\n",
    "- returns the total **number of elements** in the **array column**.\n",
    "- If your input array column is **null**, it returns **null**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e08e140-fdd3-4624-9ac4-ba76677d9bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     # 12.2 LTS (includes Apache Spark 3.3.2, Scala 2.12)\n",
    "     from pyspark.sql.functions import size\n",
    "\n",
    "     # 15.4 LTS (includes Apache Spark 3.5.0, Scala 2.12)\n",
    "     from pyspark.sql.functions import array_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "158a9297-cced-4294-85d7-8450f1204181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>LearntLanguages</th><th>ToLearnLanguages</th><th>PresentState</th><th>PreviousState</th><th>Arr_Size_01</th><th>Arr_Size_02</th><th>Arr_Size_03</th></tr></thead><tbody><tr><td>List(Java, Scala, C++)</td><td>List(Spark, Java, Azure Databricks)</td><td>Bangalore</td><td>Chennai</td><td>List(Bangalore, Chennai, 3)</td><td>List(Bangalore, 3, 3)</td><td>List(4, 3, 3)</td></tr><tr><td>List(Python, PySpark, C)</td><td>List(spark sql, ADF)</td><td>Hyderabad</td><td>Kochin</td><td>List(Hyderabad, Kochin, 2)</td><td>List(Hyderabad, 3, 2)</td><td>List(4, 3, 2)</td></tr><tr><td>List(Devops, VB, Git)</td><td>List(ApacheSpark, Python)</td><td>Amaravathi</td><td>Noida</td><td>List(Amaravathi, Noida, 2)</td><td>List(Amaravathi, 3, 2)</td><td>List(4, 3, 2)</td></tr><tr><td>List(SQL, Azure, AWS)</td><td>List(PySpark, Oracle, Confluence)</td><td>Noida</td><td>Mumbai</td><td>List(Noida, Mumbai, 3)</td><td>List(Noida, 3, 3)</td><td>List(4, 3, 3)</td></tr><tr><td>List(GCC, Visual Studio)</td><td>List(SQL, Databricks, SQL Editor)</td><td>Delhi</td><td>Kolkata</td><td>List(Delhi, Kolkata, 3)</td><td>List(Delhi, 2, 3)</td><td>List(4, 2, 3)</td></tr><tr><td>List(Devops, VB, Git)</td><td>List(ApacheSpark, Python)</td><td>Amaravathi</td><td>Noida</td><td>List(Amaravathi, Noida, 2)</td><td>List(Amaravathi, 3, 2)</td><td>List(4, 3, 2)</td></tr><tr><td>List(SQL, Azure, AWS)</td><td>List(PySpark, Oracle, Schema)</td><td>luknow</td><td>Mumbai</td><td>List(luknow, Mumbai, 3)</td><td>List(luknow, 3, 3)</td><td>List(4, 3, 3)</td></tr><tr><td>List(AWS, Visual Studio)</td><td>List(SQL, Git, SQL Editor)</td><td>Delhi</td><td>Noida</td><td>List(Delhi, Noida, 3)</td><td>List(Delhi, 2, 3)</td><td>List(4, 2, 3)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "Java",
          "Scala",
          "C++"
         ],
         [
          "Spark",
          "Java",
          "Azure Databricks"
         ],
         "Bangalore",
         "Chennai",
         [
          "Bangalore",
          "Chennai",
          "3"
         ],
         [
          "Bangalore",
          "3",
          "3"
         ],
         [
          4,
          3,
          3
         ]
        ],
        [
         [
          "Python",
          "PySpark",
          "C"
         ],
         [
          "spark sql",
          "ADF"
         ],
         "Hyderabad",
         "Kochin",
         [
          "Hyderabad",
          "Kochin",
          "2"
         ],
         [
          "Hyderabad",
          "3",
          "2"
         ],
         [
          4,
          3,
          2
         ]
        ],
        [
         [
          "Devops",
          "VB",
          "Git"
         ],
         [
          "ApacheSpark",
          "Python"
         ],
         "Amaravathi",
         "Noida",
         [
          "Amaravathi",
          "Noida",
          "2"
         ],
         [
          "Amaravathi",
          "3",
          "2"
         ],
         [
          4,
          3,
          2
         ]
        ],
        [
         [
          "SQL",
          "Azure",
          "AWS"
         ],
         [
          "PySpark",
          "Oracle",
          "Confluence"
         ],
         "Noida",
         "Mumbai",
         [
          "Noida",
          "Mumbai",
          "3"
         ],
         [
          "Noida",
          "3",
          "3"
         ],
         [
          4,
          3,
          3
         ]
        ],
        [
         [
          "GCC",
          "Visual Studio"
         ],
         [
          "SQL",
          "Databricks",
          "SQL Editor"
         ],
         "Delhi",
         "Kolkata",
         [
          "Delhi",
          "Kolkata",
          "3"
         ],
         [
          "Delhi",
          "2",
          "3"
         ],
         [
          4,
          2,
          3
         ]
        ],
        [
         [
          "Devops",
          "VB",
          "Git"
         ],
         [
          "ApacheSpark",
          "Python"
         ],
         "Amaravathi",
         "Noida",
         [
          "Amaravathi",
          "Noida",
          "2"
         ],
         [
          "Amaravathi",
          "3",
          "2"
         ],
         [
          4,
          3,
          2
         ]
        ],
        [
         [
          "SQL",
          "Azure",
          "AWS"
         ],
         [
          "PySpark",
          "Oracle",
          "Schema"
         ],
         "luknow",
         "Mumbai",
         [
          "luknow",
          "Mumbai",
          "3"
         ],
         [
          "luknow",
          "3",
          "3"
         ],
         [
          4,
          3,
          3
         ]
        ],
        [
         [
          "AWS",
          "Visual Studio"
         ],
         [
          "SQL",
          "Git",
          "SQL Editor"
         ],
         "Delhi",
         "Noida",
         [
          "Delhi",
          "Noida",
          "3"
         ],
         [
          "Delhi",
          "2",
          "3"
         ],
         [
          4,
          2,
          3
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "LearntLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "ToLearnLanguages",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "PresentState",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "PreviousState",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Arr_Size_01",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Arr_Size_02",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Arr_Size_03",
         "type": "{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.withColumn(\"Arr_Size_01\", array(\"PresentState\", \"PreviousState\", size(\"ToLearnLanguages\")))\\\n",
    "           .withColumn(\"Arr_Size_02\", array(\"PresentState\", size(\"LearntLanguages\"), size(\"ToLearnLanguages\")))\\\n",
    "           .withColumn(\"Arr_Size_03\", array(size(\"Rating\"), size(\"LearntLanguages\"), size(\"ToLearnLanguages\")))\\\n",
    "           .select(\"LearntLanguages\", \"ToLearnLanguages\", \"PresentState\", \"PreviousState\", \"Arr_Size_01\", \"Arr_Size_02\", \"Arr_Size_03\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "51_How to access array elements",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
