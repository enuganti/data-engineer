{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72641fef-34a2-4af3-92d8-121bd71bf09b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, explode_outer\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b692ce-621e-49e5-859e-b96c9379cdbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------------+\n|id |Name    |skills                      |\n+---+--------+----------------------------+\n|1  |Suresh  |[.net, Python, Spark, Azure]|\n|2  |Ramya   |[java, PySpark, AWS]        |\n|3  |Rakesh  |[ADF, SQL, null, GCC]       |\n|4  |Apurba  |[C, SAP, Mainframes]        |\n|5  |Pranitha|[COBOL, DEVOPS]             |\n|6  |Sowmya  |[ABAP]                      |\n|7  |Anand   |null                        |\n|8  |Sourabh |[]                          |\n+---+--------+----------------------------+\n\nroot\n |-- id: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- skills: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\nNumber of Rows: 8\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Suresh\", [\".net\", \"Python\", \"Spark\", \"Azure\"]),\n",
    "    (2, \"Ramya\", [\"java\", \"PySpark\", \"AWS\"]),\n",
    "    (3, \"Rakesh\", [\"ADF\", \"SQL\", None, \"GCC\"]),\n",
    "    (4, \"Apurba\", [\"C\", \"SAP\", \"Mainframes\"]),\n",
    "    (5, \"Pranitha\", [\"COBOL\", \"DEVOPS\"]),\n",
    "    (6, \"Sowmya\", [\"ABAP\"]),\n",
    "    (7, \"Anand\", None),\n",
    "    (8, \"Sourabh\", []),\n",
    "]\n",
    "schema = [\"id\", \"Name\", \"skills\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)\n",
    "df.printSchema()\n",
    "print(\"Number of Rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aac3523-f49e-40d5-b4fe-b8b962c45463",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------------+\n|id |Name    |skills                      |\n+---+--------+----------------------------+\n|1  |Suresh  |[.net, Python, Spark, Azure]|\n|2  |Ramya   |[java, PySpark, AWS]        |\n|3  |Rakesh  |[ADF, SQL, null, GCC]       |\n|4  |Apurba  |[C, SAP, Mainframes]        |\n|5  |Pranitha|[COBOL, DEVOPS]             |\n|6  |Sowmya  |[ABAP]                      |\n|7  |Anand   |null                        |\n|8  |Sourabh |[]                          |\n+---+--------+----------------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>Name</th><th>skills</th></tr></thead><tbody><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td></tr><tr><td>2</td><td>Ramya</td><td>List(java, PySpark, AWS)</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td></tr><tr><td>4</td><td>Apurba</td><td>List(C, SAP, Mainframes)</td></tr><tr><td>5</td><td>Pranitha</td><td>List(COBOL, DEVOPS)</td></tr><tr><td>6</td><td>Sowmya</td><td>List(ABAP)</td></tr><tr><td>7</td><td>Anand</td><td>null</td></tr><tr><td>8</td><td>Sourabh</td><td>List()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ]
        ],
        [
         2,
         "Ramya",
         [
          "java",
          "PySpark",
          "AWS"
         ]
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ]
        ],
        [
         4,
         "Apurba",
         [
          "C",
          "SAP",
          "Mainframes"
         ]
        ],
        [
         5,
         "Pranitha",
         [
          "COBOL",
          "DEVOPS"
         ]
        ],
        [
         6,
         "Sowmya",
         [
          "ABAP"
         ]
        ],
        [
         7,
         "Anand",
         null
        ],
        [
         8,
         "Sourabh",
         []
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "skills",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.show(truncate=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211285c6-ff08-49e8-8ad5-4658a9e6265b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>Name</th><th>skills</th><th>New-Skills</th></tr></thead><tbody><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td><td>.net</td></tr><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td><td>Python</td></tr><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td><td>Spark</td></tr><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td><td>Azure</td></tr><tr><td>2</td><td>Ramya</td><td>List(java, PySpark, AWS)</td><td>java</td></tr><tr><td>2</td><td>Ramya</td><td>List(java, PySpark, AWS)</td><td>PySpark</td></tr><tr><td>2</td><td>Ramya</td><td>List(java, PySpark, AWS)</td><td>AWS</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td><td>ADF</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td><td>SQL</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td><td>null</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td><td>GCC</td></tr><tr><td>4</td><td>Apurba</td><td>List(C, SAP, Mainframes)</td><td>C</td></tr><tr><td>4</td><td>Apurba</td><td>List(C, SAP, Mainframes)</td><td>SAP</td></tr><tr><td>4</td><td>Apurba</td><td>List(C, SAP, Mainframes)</td><td>Mainframes</td></tr><tr><td>5</td><td>Pranitha</td><td>List(COBOL, DEVOPS)</td><td>COBOL</td></tr><tr><td>5</td><td>Pranitha</td><td>List(COBOL, DEVOPS)</td><td>DEVOPS</td></tr><tr><td>6</td><td>Sowmya</td><td>List(ABAP)</td><td>ABAP</td></tr><tr><td>7</td><td>Anand</td><td>null</td><td>null</td></tr><tr><td>8</td><td>Sourabh</td><td>List()</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ],
         ".net"
        ],
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ],
         "Python"
        ],
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ],
         "Spark"
        ],
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ],
         "Azure"
        ],
        [
         2,
         "Ramya",
         [
          "java",
          "PySpark",
          "AWS"
         ],
         "java"
        ],
        [
         2,
         "Ramya",
         [
          "java",
          "PySpark",
          "AWS"
         ],
         "PySpark"
        ],
        [
         2,
         "Ramya",
         [
          "java",
          "PySpark",
          "AWS"
         ],
         "AWS"
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ],
         "ADF"
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ],
         "SQL"
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ],
         null
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ],
         "GCC"
        ],
        [
         4,
         "Apurba",
         [
          "C",
          "SAP",
          "Mainframes"
         ],
         "C"
        ],
        [
         4,
         "Apurba",
         [
          "C",
          "SAP",
          "Mainframes"
         ],
         "SAP"
        ],
        [
         4,
         "Apurba",
         [
          "C",
          "SAP",
          "Mainframes"
         ],
         "Mainframes"
        ],
        [
         5,
         "Pranitha",
         [
          "COBOL",
          "DEVOPS"
         ],
         "COBOL"
        ],
        [
         5,
         "Pranitha",
         [
          "COBOL",
          "DEVOPS"
         ],
         "DEVOPS"
        ],
        [
         6,
         "Sowmya",
         [
          "ABAP"
         ],
         "ABAP"
        ],
        [
         7,
         "Anand",
         null,
         null
        ],
        [
         8,
         "Sourabh",
         [],
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "skills",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "New-Skills",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- skills: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- New-Skills: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"New-Skills\", explode_outer(col('skills')))\n",
    "display(df)\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "12_Databricks_Pyspark: Difference btn Explode and Explode_Outer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
