{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd8791f-1dc4-413b-8728-afc9adf94319",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **posexplode_outer**\n",
    "- Returns a **new row** for **each element** in the given **array**.\n",
    "- It creates a **row for each element** in the array and creates two columns **pos** to hold the **position of the array element** and the **col** to hold the **actual array value**.\n",
    "- When the input column is **map**, posexplode function creates 3 columns **pos** to hold the **position of the map element**, **key and value** columns.\n",
    "- Unlike posexplode, \n",
    "  - if the **array/map** is **NULL /Empty** posexplode_outer function returns **NULL**, NULL for **pos and col** columns.\n",
    "  - Similarly for the **map** it returns **rows with NULL's**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "036ce8dd-a534-45ff-9dac-23e054db794f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, posexplode, posexplode_outer, split\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c686de3-3972-427a-b3b5-9bb6cfa9e8a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Array Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b515a875-4c05-4171-818b-49e3129d39e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------------------+\n|id |Name    |skills                      |\n+---+--------+----------------------------+\n|1  |Suresh  |[.net, Python, Spark, Azure]|\n|2  |Ramya   |[java, PySpark, AWS]        |\n|3  |Rakesh  |[ADF, SQL, null, GCC]       |\n|4  |Apurba  |[C, SAP, null]              |\n|5  |Pranitha|[COBOL, DEVOPS]             |\n|6  |Sowmya  |[ABAP, null]                |\n|7  |Anand   |null                        |\n|8  |Sourabh |[]                          |\n+---+--------+----------------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>Name</th><th>skills</th></tr></thead><tbody><tr><td>1</td><td>Suresh</td><td>List(.net, Python, Spark, Azure)</td></tr><tr><td>2</td><td>Ramya</td><td>List(java, PySpark, AWS)</td></tr><tr><td>3</td><td>Rakesh</td><td>List(ADF, SQL, null, GCC)</td></tr><tr><td>4</td><td>Apurba</td><td>List(C, SAP, null)</td></tr><tr><td>5</td><td>Pranitha</td><td>List(COBOL, DEVOPS)</td></tr><tr><td>6</td><td>Sowmya</td><td>List(ABAP, null)</td></tr><tr><td>7</td><td>Anand</td><td>null</td></tr><tr><td>8</td><td>Sourabh</td><td>List()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Suresh",
         [
          ".net",
          "Python",
          "Spark",
          "Azure"
         ]
        ],
        [
         2,
         "Ramya",
         [
          "java",
          "PySpark",
          "AWS"
         ]
        ],
        [
         3,
         "Rakesh",
         [
          "ADF",
          "SQL",
          null,
          "GCC"
         ]
        ],
        [
         4,
         "Apurba",
         [
          "C",
          "SAP",
          null
         ]
        ],
        [
         5,
         "Pranitha",
         [
          "COBOL",
          "DEVOPS"
         ]
        ],
        [
         6,
         "Sowmya",
         [
          "ABAP",
          null
         ]
        ],
        [
         7,
         "Anand",
         null
        ],
        [
         8,
         "Sourabh",
         []
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "skills",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- skills: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\nNumber of Rows: 8\n"
     ]
    }
   ],
   "source": [
    "data = [(1, \"Suresh\", [\".net\", \"Python\", \"Spark\", \"Azure\"]),\n",
    "        (2, \"Ramya\", [\"java\", \"PySpark\", \"AWS\"]),\n",
    "        (3, \"Rakesh\", [\"ADF\", \"SQL\", None, \"GCC\"]),\n",
    "        (4, \"Apurba\", [\"C\", \"SAP\", None]),\n",
    "        (5, \"Pranitha\", [\"COBOL\", \"DEVOPS\"]),\n",
    "        (6, \"Sowmya\", [\"ABAP\", None]),\n",
    "        (7, \"Anand\", None),\n",
    "        (8, \"Sourabh\", [])]\n",
    "schema = [\"id\", \"Name\", \"skills\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)\n",
    "display(df)\n",
    "df.printSchema()\n",
    "print(\"Number of Rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2bffcd5-fca5-41b8-87d5-2df43a9986e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Name</th><th>pos</th><th>col</th></tr></thead><tbody><tr><td>Suresh</td><td>0</td><td>.net</td></tr><tr><td>Suresh</td><td>1</td><td>Python</td></tr><tr><td>Suresh</td><td>2</td><td>Spark</td></tr><tr><td>Suresh</td><td>3</td><td>Azure</td></tr><tr><td>Ramya</td><td>0</td><td>java</td></tr><tr><td>Ramya</td><td>1</td><td>PySpark</td></tr><tr><td>Ramya</td><td>2</td><td>AWS</td></tr><tr><td>Rakesh</td><td>0</td><td>ADF</td></tr><tr><td>Rakesh</td><td>1</td><td>SQL</td></tr><tr><td>Rakesh</td><td>2</td><td>null</td></tr><tr><td>Rakesh</td><td>3</td><td>GCC</td></tr><tr><td>Apurba</td><td>0</td><td>C</td></tr><tr><td>Apurba</td><td>1</td><td>SAP</td></tr><tr><td>Apurba</td><td>2</td><td>null</td></tr><tr><td>Pranitha</td><td>0</td><td>COBOL</td></tr><tr><td>Pranitha</td><td>1</td><td>DEVOPS</td></tr><tr><td>Sowmya</td><td>0</td><td>ABAP</td></tr><tr><td>Sowmya</td><td>1</td><td>null</td></tr><tr><td>Anand</td><td>null</td><td>null</td></tr><tr><td>Sourabh</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Suresh",
         0,
         ".net"
        ],
        [
         "Suresh",
         1,
         "Python"
        ],
        [
         "Suresh",
         2,
         "Spark"
        ],
        [
         "Suresh",
         3,
         "Azure"
        ],
        [
         "Ramya",
         0,
         "java"
        ],
        [
         "Ramya",
         1,
         "PySpark"
        ],
        [
         "Ramya",
         2,
         "AWS"
        ],
        [
         "Rakesh",
         0,
         "ADF"
        ],
        [
         "Rakesh",
         1,
         "SQL"
        ],
        [
         "Rakesh",
         2,
         null
        ],
        [
         "Rakesh",
         3,
         "GCC"
        ],
        [
         "Apurba",
         0,
         "C"
        ],
        [
         "Apurba",
         1,
         "SAP"
        ],
        [
         "Apurba",
         2,
         null
        ],
        [
         "Pranitha",
         0,
         "COBOL"
        ],
        [
         "Pranitha",
         1,
         "DEVOPS"
        ],
        [
         "Sowmya",
         0,
         "ABAP"
        ],
        [
         "Sowmya",
         1,
         null
        ],
        [
         "Anand",
         null,
         null
        ],
        [
         "Sourabh",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "pos",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "col",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.select(df.Name, posexplode_outer(df.skills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a1c3c6a-299a-4c22-bd13-286c873b6789",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Map Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e41d3df3-24f8-47ac-8325-95876914a6e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>brand</th></tr></thead><tbody><tr><td>Raja</td><td>Map(Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips)</td></tr><tr><td>Raghav</td><td>Map(AC -> Samsung, Washing machine -> LG)</td></tr><tr><td>Ram</td><td>Map(TV -> , Grinder -> Preeti)</td></tr><tr><td>Ramesh</td><td>Map(Refrigerator -> LG, TV -> Croma)</td></tr><tr><td>Rajesh</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Raja",
         {
          "AC": "Voltas",
          "Oven": "Philips",
          "Refrigerator": "Samsung",
          "TV": "LG"
         }
        ],
        [
         "Raghav",
         {
          "AC": "Samsung",
          "Washing machine": "LG"
         }
        ],
        [
         "Ram",
         {
          "Grinder": "Preeti",
          "TV": ""
         }
        ],
        [
         "Ramesh",
         {
          "Refrigerator": "LG",
          "TV": "Croma"
         }
        ],
        [
         "Rajesh",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "brand",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------------------------------------+\n|name  |brand                                                             |\n+------+------------------------------------------------------------------+\n|Raja  |{Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips}|\n|Raghav|{AC -> Samsung, Washing machine -> LG}                            |\n|Ram   |{TV -> , Grinder -> Preeti}                                       |\n|Ramesh|{Refrigerator -> LG, TV -> Croma}                                 |\n|Rajesh|null                                                              |\n+------+------------------------------------------------------------------+\n\nroot\n |-- name: string (nullable = true)\n |-- brand: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\nNumber of Rows: 5\n"
     ]
    }
   ],
   "source": [
    "data1 = [('Raja', {'TV':'LG', 'Refrigerator':'Samsung', 'Oven':'Philips', 'AC':'Voltas'}),\n",
    "        ('Raghav', {'AC':'Samsung', 'Washing machine': 'LG'}),\n",
    "        ('Ram', {'Grinder':'Preeti', 'TV':\"\"}),\n",
    "        ('Ramesh', {'Refrigerator':'LG', 'TV':'Croma'}),\n",
    "        ('Rajesh', None)]\n",
    "\n",
    "schema1 = ['name', 'brand']\n",
    "\n",
    "df1 = spark.createDataFrame(data=data1, schema=schema1)\n",
    "display(df1)\n",
    "df1.show(truncate=False)\n",
    "df1.printSchema()\n",
    "print(\"Number of Rows:\", df1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191b030a-f737-4754-adc6-3b5faa7ad26d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>brand</th><th>pos</th><th>key</th><th>value</th></tr></thead><tbody><tr><td>Raja</td><td>Map(Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips)</td><td>0</td><td>Refrigerator</td><td>Samsung</td></tr><tr><td>Raja</td><td>Map(Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips)</td><td>1</td><td>AC</td><td>Voltas</td></tr><tr><td>Raja</td><td>Map(Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips)</td><td>2</td><td>TV</td><td>LG</td></tr><tr><td>Raja</td><td>Map(Refrigerator -> Samsung, AC -> Voltas, TV -> LG, Oven -> Philips)</td><td>3</td><td>Oven</td><td>Philips</td></tr><tr><td>Raghav</td><td>Map(AC -> Samsung, Washing machine -> LG)</td><td>0</td><td>AC</td><td>Samsung</td></tr><tr><td>Raghav</td><td>Map(AC -> Samsung, Washing machine -> LG)</td><td>1</td><td>Washing machine</td><td>LG</td></tr><tr><td>Ram</td><td>Map(TV -> , Grinder -> Preeti)</td><td>0</td><td>TV</td><td></td></tr><tr><td>Ram</td><td>Map(TV -> , Grinder -> Preeti)</td><td>1</td><td>Grinder</td><td>Preeti</td></tr><tr><td>Ramesh</td><td>Map(Refrigerator -> LG, TV -> Croma)</td><td>0</td><td>Refrigerator</td><td>LG</td></tr><tr><td>Ramesh</td><td>Map(Refrigerator -> LG, TV -> Croma)</td><td>1</td><td>TV</td><td>Croma</td></tr><tr><td>Rajesh</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Raja",
         {
          "AC": "Voltas",
          "Oven": "Philips",
          "Refrigerator": "Samsung",
          "TV": "LG"
         },
         0,
         "Refrigerator",
         "Samsung"
        ],
        [
         "Raja",
         {
          "AC": "Voltas",
          "Oven": "Philips",
          "Refrigerator": "Samsung",
          "TV": "LG"
         },
         1,
         "AC",
         "Voltas"
        ],
        [
         "Raja",
         {
          "AC": "Voltas",
          "Oven": "Philips",
          "Refrigerator": "Samsung",
          "TV": "LG"
         },
         2,
         "TV",
         "LG"
        ],
        [
         "Raja",
         {
          "AC": "Voltas",
          "Oven": "Philips",
          "Refrigerator": "Samsung",
          "TV": "LG"
         },
         3,
         "Oven",
         "Philips"
        ],
        [
         "Raghav",
         {
          "AC": "Samsung",
          "Washing machine": "LG"
         },
         0,
         "AC",
         "Samsung"
        ],
        [
         "Raghav",
         {
          "AC": "Samsung",
          "Washing machine": "LG"
         },
         1,
         "Washing machine",
         "LG"
        ],
        [
         "Ram",
         {
          "Grinder": "Preeti",
          "TV": ""
         },
         0,
         "TV",
         ""
        ],
        [
         "Ram",
         {
          "Grinder": "Preeti",
          "TV": ""
         },
         1,
         "Grinder",
         "Preeti"
        ],
        [
         "Ramesh",
         {
          "Refrigerator": "LG",
          "TV": "Croma"
         },
         0,
         "Refrigerator",
         "LG"
        ],
        [
         "Ramesh",
         {
          "Refrigerator": "LG",
          "TV": "Croma"
         },
         1,
         "TV",
         "Croma"
        ],
        [
         "Rajesh",
         null,
         null,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "brand",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "pos",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1.select(df1.name, df1.brand, posexplode_outer(df1.brand)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c027ffd8-0a3a-4b8f-9c8b-9b1571bc8c30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679e5570-e654-4c7e-9d5f-cc3c4a1f7d2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>S.No</th><th>EmpName</th><th>Dept</th><th>Technology</th><th>Age</th><th>Year</th></tr></thead><tbody><tr><td>1</td><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>30</td><td>2022</td></tr><tr><td>2</td><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>35</td><td>2023</td></tr><tr><td>3</td><td>Amar</td><td>Azure</td><td>ADB, None, PySpark</td><td>40</td><td>2021</td></tr><tr><td>4</td><td>Rakesh</td><td>Azure</td><td>ADB, ADF</td><td>33</td><td>2023</td></tr><tr><td>5</td><td>Royal</td><td>Azure</td><td>ADB, None</td><td>35</td><td>2022</td></tr><tr><td>6</td><td>Swapnil</td><td>AWS</td><td>null</td><td>38</td><td>2002</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         30,
         2022
        ],
        [
         2,
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         35,
         2023
        ],
        [
         3,
         "Amar",
         "Azure",
         "ADB, None, PySpark",
         40,
         2021
        ],
        [
         4,
         "Rakesh",
         "Azure",
         "ADB, ADF",
         33,
         2023
        ],
        [
         5,
         "Royal",
         "Azure",
         "ADB, None",
         35,
         2022
        ],
        [
         6,
         "Swapnil",
         "AWS",
         null,
         38,
         2002
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "S.No",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "EmpName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Year",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = spark.read.csv(\"/FileStore/tables/posexplode.txt\", sep=\"|\", header=True, inferSchema=True)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "052dc5be-0594-4fc4-8aa6-43647ac7b085",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmpName</th><th>Dept</th><th>Technology</th><th>New_Technology</th></tr></thead><tbody><tr><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>List(ADB,  ADF,  PySpark,  SQL)</td></tr><tr><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>List(None,  ADF,  PySpark,  SQL)</td></tr><tr><td>Amar</td><td>Azure</td><td>ADB, None, PySpark</td><td>List(ADB,  None,  PySpark)</td></tr><tr><td>Rakesh</td><td>Azure</td><td>ADB, ADF</td><td>List(ADB,  ADF)</td></tr><tr><td>Royal</td><td>Azure</td><td>ADB, None</td><td>List(ADB,  None)</td></tr><tr><td>Swapnil</td><td>AWS</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         [
          "ADB",
          " ADF",
          " PySpark",
          " SQL"
         ]
        ],
        [
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         [
          "None",
          " ADF",
          " PySpark",
          " SQL"
         ]
        ],
        [
         "Amar",
         "Azure",
         "ADB, None, PySpark",
         [
          "ADB",
          " None",
          " PySpark"
         ]
        ],
        [
         "Rakesh",
         "Azure",
         "ADB, ADF",
         [
          "ADB",
          " ADF"
         ]
        ],
        [
         "Royal",
         "Azure",
         "ADB, None",
         [
          "ADB",
          " None"
         ]
        ],
        [
         "Swapnil",
         "AWS",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmpName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "New_Technology",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":false}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df2.withColumn(\"New_Technology\", split((\"Technology\"), ',')).select('EmpName', 'Dept', 'Technology', 'New_Technology')\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b68f16-50f2-4242-ba7a-4ccd23043743",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmpName</th><th>Dept</th><th>Technology</th><th>New_Technology</th><th>pos</th><th>col</th></tr></thead><tbody><tr><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>List(ADB,  ADF,  PySpark,  SQL)</td><td>0</td><td>ADB</td></tr><tr><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>List(ADB,  ADF,  PySpark,  SQL)</td><td>1</td><td> ADF</td></tr><tr><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>List(ADB,  ADF,  PySpark,  SQL)</td><td>2</td><td> PySpark</td></tr><tr><td>Sundar</td><td>Azure</td><td>ADB, ADF, PySpark, SQL</td><td>List(ADB,  ADF,  PySpark,  SQL)</td><td>3</td><td> SQL</td></tr><tr><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>List(None,  ADF,  PySpark,  SQL)</td><td>0</td><td>None</td></tr><tr><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>List(None,  ADF,  PySpark,  SQL)</td><td>1</td><td> ADF</td></tr><tr><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>List(None,  ADF,  PySpark,  SQL)</td><td>2</td><td> PySpark</td></tr><tr><td>Sheetal</td><td>Azure</td><td>None, ADF, PySpark, SQL</td><td>List(None,  ADF,  PySpark,  SQL)</td><td>3</td><td> SQL</td></tr><tr><td>Amar</td><td>Azure</td><td>ADB, None, PySpark</td><td>List(ADB,  None,  PySpark)</td><td>0</td><td>ADB</td></tr><tr><td>Amar</td><td>Azure</td><td>ADB, None, PySpark</td><td>List(ADB,  None,  PySpark)</td><td>1</td><td> None</td></tr><tr><td>Amar</td><td>Azure</td><td>ADB, None, PySpark</td><td>List(ADB,  None,  PySpark)</td><td>2</td><td> PySpark</td></tr><tr><td>Rakesh</td><td>Azure</td><td>ADB, ADF</td><td>List(ADB,  ADF)</td><td>0</td><td>ADB</td></tr><tr><td>Rakesh</td><td>Azure</td><td>ADB, ADF</td><td>List(ADB,  ADF)</td><td>1</td><td> ADF</td></tr><tr><td>Royal</td><td>Azure</td><td>ADB, None</td><td>List(ADB,  None)</td><td>0</td><td>ADB</td></tr><tr><td>Royal</td><td>Azure</td><td>ADB, None</td><td>List(ADB,  None)</td><td>1</td><td> None</td></tr><tr><td>Swapnil</td><td>AWS</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         [
          "ADB",
          " ADF",
          " PySpark",
          " SQL"
         ],
         0,
         "ADB"
        ],
        [
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         [
          "ADB",
          " ADF",
          " PySpark",
          " SQL"
         ],
         1,
         " ADF"
        ],
        [
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         [
          "ADB",
          " ADF",
          " PySpark",
          " SQL"
         ],
         2,
         " PySpark"
        ],
        [
         "Sundar",
         "Azure",
         "ADB, ADF, PySpark, SQL",
         [
          "ADB",
          " ADF",
          " PySpark",
          " SQL"
         ],
         3,
         " SQL"
        ],
        [
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         [
          "None",
          " ADF",
          " PySpark",
          " SQL"
         ],
         0,
         "None"
        ],
        [
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         [
          "None",
          " ADF",
          " PySpark",
          " SQL"
         ],
         1,
         " ADF"
        ],
        [
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         [
          "None",
          " ADF",
          " PySpark",
          " SQL"
         ],
         2,
         " PySpark"
        ],
        [
         "Sheetal",
         "Azure",
         "None, ADF, PySpark, SQL",
         [
          "None",
          " ADF",
          " PySpark",
          " SQL"
         ],
         3,
         " SQL"
        ],
        [
         "Amar",
         "Azure",
         "ADB, None, PySpark",
         [
          "ADB",
          " None",
          " PySpark"
         ],
         0,
         "ADB"
        ],
        [
         "Amar",
         "Azure",
         "ADB, None, PySpark",
         [
          "ADB",
          " None",
          " PySpark"
         ],
         1,
         " None"
        ],
        [
         "Amar",
         "Azure",
         "ADB, None, PySpark",
         [
          "ADB",
          " None",
          " PySpark"
         ],
         2,
         " PySpark"
        ],
        [
         "Rakesh",
         "Azure",
         "ADB, ADF",
         [
          "ADB",
          " ADF"
         ],
         0,
         "ADB"
        ],
        [
         "Rakesh",
         "Azure",
         "ADB, ADF",
         [
          "ADB",
          " ADF"
         ],
         1,
         " ADF"
        ],
        [
         "Royal",
         "Azure",
         "ADB, None",
         [
          "ADB",
          " None"
         ],
         0,
         "ADB"
        ],
        [
         "Royal",
         "Azure",
         "ADB, None",
         [
          "ADB",
          " None"
         ],
         1,
         " None"
        ],
        [
         "Swapnil",
         "AWS",
         null,
         null,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmpName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "New_Technology",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":false}"
        },
        {
         "metadata": "{}",
         "name": "pos",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "col",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df2.select(\"*\", posexplode_outer(\"New_Technology\"))\n",
    "display(df3)\n",
    "\n",
    "# df3 = df2.select(\"*\", posexplode_outer(split((\"Technology\"), ',')))\n",
    "# display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "483640c1-4f6d-4fcd-ab14-7acb6b50e816",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmpName</th><th>Dept</th><th>Index</th><th>CoreTechnology</th></tr></thead><tbody><tr><td>Sundar</td><td>Azure</td><td>0</td><td>ADB</td></tr><tr><td>Sundar</td><td>Azure</td><td>1</td><td> ADF</td></tr><tr><td>Sundar</td><td>Azure</td><td>2</td><td> PySpark</td></tr><tr><td>Sundar</td><td>Azure</td><td>3</td><td> SQL</td></tr><tr><td>Sheetal</td><td>Azure</td><td>0</td><td>None</td></tr><tr><td>Sheetal</td><td>Azure</td><td>1</td><td> ADF</td></tr><tr><td>Sheetal</td><td>Azure</td><td>2</td><td> PySpark</td></tr><tr><td>Sheetal</td><td>Azure</td><td>3</td><td> SQL</td></tr><tr><td>Amar</td><td>Azure</td><td>0</td><td>ADB</td></tr><tr><td>Amar</td><td>Azure</td><td>1</td><td> None</td></tr><tr><td>Amar</td><td>Azure</td><td>2</td><td> PySpark</td></tr><tr><td>Rakesh</td><td>Azure</td><td>0</td><td>ADB</td></tr><tr><td>Rakesh</td><td>Azure</td><td>1</td><td> ADF</td></tr><tr><td>Royal</td><td>Azure</td><td>0</td><td>ADB</td></tr><tr><td>Royal</td><td>Azure</td><td>1</td><td> None</td></tr><tr><td>Swapnil</td><td>AWS</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Sundar",
         "Azure",
         0,
         "ADB"
        ],
        [
         "Sundar",
         "Azure",
         1,
         " ADF"
        ],
        [
         "Sundar",
         "Azure",
         2,
         " PySpark"
        ],
        [
         "Sundar",
         "Azure",
         3,
         " SQL"
        ],
        [
         "Sheetal",
         "Azure",
         0,
         "None"
        ],
        [
         "Sheetal",
         "Azure",
         1,
         " ADF"
        ],
        [
         "Sheetal",
         "Azure",
         2,
         " PySpark"
        ],
        [
         "Sheetal",
         "Azure",
         3,
         " SQL"
        ],
        [
         "Amar",
         "Azure",
         0,
         "ADB"
        ],
        [
         "Amar",
         "Azure",
         1,
         " None"
        ],
        [
         "Amar",
         "Azure",
         2,
         " PySpark"
        ],
        [
         "Rakesh",
         "Azure",
         0,
         "ADB"
        ],
        [
         "Rakesh",
         "Azure",
         1,
         " ADF"
        ],
        [
         "Royal",
         "Azure",
         0,
         "ADB"
        ],
        [
         "Royal",
         "Azure",
         1,
         " None"
        ],
        [
         "Swapnil",
         "AWS",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmpName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Index",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "CoreTechnology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df3.withColumnRenamed(\"col\", \"CoreTechnology\")\\\n",
    "         .withColumnRenamed(\"pos\", \"Index\")\\\n",
    "         .drop(\"Technology\", \"New_Technology\")        \n",
    "display(df3)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "13_Databricks_Pyspark Difference bn posexplode and posexplode_outer_02",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
