{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921f59f0-5950-41ca-b7aa-e48a5b19bf7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### **union(), unionAll() & unionByName()**\n",
    "\n",
    "**PySpark “2.0.0”**\n",
    "\n",
    "- **union()**\n",
    "  - **Removes** the **duplicate records** from resultant dataframe until **spark version 2.0.0**. So duplicate can be removed manually by **dropDuplicates()**.\n",
    "\n",
    "- **unionAll()**\n",
    "  - Same as union but **retains duplicate records** as well in resultant dataframe.\n",
    "\n",
    "**union():** \n",
    "- Combines **two DataFrames** have the **same column order and schema**.\n",
    "\n",
    "    - **union() and unionAll()** transformations are used to **merge two or more DataFrame’s** of the **same schema or structure**.\n",
    "    - The output includes `all rows from both DataFrames` and **duplicates are retained**.\n",
    "    - If schemas are `not the same it returns an error`.\n",
    "\n",
    "**unionAll():**\n",
    "  - Alias for union(), behaves the same.\n",
    "  - **unionAll()** method is **deprecated** since **PySpark “2.0.0”** version and **recommends** using the **union()** method.\n",
    "\n",
    "**unionByName():**\n",
    "- Combines two DataFrames by matching **column names**, even **if column order differs**.\n",
    "- To deal with the DataFrames of **different schemas** we need to use **unionByName()** transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d87a0323-30b8-4289-b92c-0a500df7518d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**When to Use What?**\n",
    "\n",
    "- Use **union() or unionAll()** when **schemas and column orders** are the **same**.\n",
    "- Use **unionByName()** when **column names** are the **same** but their **order** might be **different**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd51c8a-095b-4c3d-9ac0-234958f52e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Key Differences**\n",
    "\n",
    "         |   Function    |    Same Schema\t|  Same Column Order\t|  Matches Column Names  |\n",
    "         |---------------|------------------|-----------------------|------------------------|\n",
    "         | union()\t     |   ✅ Required\t|   ✅ Required\t        |   ❌ No Matching       |\n",
    "         | unionAll()    |   ✅ Required    |   ✅ Required\t        |   ❌ No Matching       |\n",
    "         | unionByName() |   ✅ Required\t|   ❌ Not Required\t|   ✅ Matches Columns   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "150b6910-364b-4f71-9504-d910c4a4f948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Syntax**\n",
    "\n",
    "     df1.union(df2)\n",
    "     df1.unionAll(df2)\n",
    "     df1.unionByName(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4643323-db3a-427a-a763-4734b2cf4021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "\n",
    "# Get Spark version\n",
    "print(spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1cb8b7-44b7-415e-bafd-f19d3de95407",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dataframe 01"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simpleData = [(\"Kiran\", \"Sales\", \"AP\", 890000, 24, 35000), \\\n",
    "              (\"Mohan\", \"Admin\", \"TN\", 756000, 36, 45000), \\\n",
    "              (\"Robert\", \"Marketing\", \"KA\", 567000, 33, 35000), \\\n",
    "              (\"Swetha\", \"Finance\", \"PNB\", 598000, 26, 99000), \\\n",
    "              (\"Kamalesh\", \"IT\", \"TS\", 8946000, 31, 56000), \\\n",
    "              (\"Mathew\", \"Maintenance\", \"KL\", 667000, 28, 467000), \\\n",
    "              (\"Santhosh\", \"Sales\", \"MH\", 873000, 24, 734000),\\\n",
    "              (\"Swetha\", \"Finance\", \"PNB\", 598000, 26, 99000), \\\n",
    "              (\"Mohan\", \"Admin\", \"TN\", 756000, 36, 45000)\n",
    "              ]\n",
    "\n",
    "columns= [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df1.printSchema()\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22d4fea-2cf6-44e2-b6cd-b75a63e668c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dataframe 02"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame2\n",
    "simpleData2 = [(\"Kailash\", \"Sales\", \"RJ\", 96600, 30, 15500), \\\n",
    "               (\"Somesh\", \"Finance\", \"UP\", 88000, 22, 27800), \\\n",
    "               (\"Jennifer\", \"Support\", \"TN\", 59000, 43, 35500), \\\n",
    "               (\"Kumar\", \"Marketing\", \"CA\", 768000, 28, 945000), \\\n",
    "               (\"Sandya\", \"IT\", \"PNB\", 789000, 37, 678900), \\\n",
    "               (\"Swaroop\", \"Admin\", \"KL\", 679000, 24, 478000), \\\n",
    "               (\"Joseph\", \"Finance\", \"DL\", 789000, 29, 456700), \\\n",
    "               (\"Rashi\", \"Maintenance\", \"TS\", 467800, 23, 872300), \\\n",
    "               (\"Krishna\", \"Backend\", \"AP\", 945670, 39, 435000),\\\n",
    "               (\"Sandya\", \"IT\", \"PNB\", 789000, 37, 678900), \\\n",
    "               (\"Swaroop\", \"Admin\", \"KL\", 679000, 24, 478000)\n",
    "               ]\n",
    "columns2= [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data = simpleData2, schema = columns2)\n",
    "\n",
    "df2.printSchema()\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "404059aa-8373-4025-927e-64b9ccbbea79",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dataframe 04"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- department: string (nullable = true)\n |-- age: long (nullable = true)\n |-- state: string (nullable = true)\n |-- bonus: long (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>salary</th><th>department</th><th>age</th><th>state</th><th>bonus</th></tr></thead><tbody><tr><td>Kailash</td><td>96600</td><td>Sales</td><td>30</td><td>RJ</td><td>15500</td></tr><tr><td>Somesh</td><td>88000</td><td>Finance</td><td>22</td><td>UP</td><td>27800</td></tr><tr><td>Jennifer</td><td>59000</td><td>Support</td><td>43</td><td>TN</td><td>35500</td></tr><tr><td>Kumar</td><td>768000</td><td>Marketing</td><td>28</td><td>CA</td><td>945000</td></tr><tr><td>Sandya</td><td>789000</td><td>IT</td><td>37</td><td>PNB</td><td>678900</td></tr><tr><td>Swaroop</td><td>679000</td><td>Admin</td><td>24</td><td>KL</td><td>478000</td></tr><tr><td>Joseph</td><td>789000</td><td>Finance</td><td>29</td><td>DL</td><td>456700</td></tr><tr><td>Rashi</td><td>467800</td><td>Maintenance</td><td>23</td><td>TS</td><td>872300</td></tr><tr><td>Krishna</td><td>945670</td><td>Backend</td><td>39</td><td>AP</td><td>435000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kailash",
         96600,
         "Sales",
         30,
         "RJ",
         15500
        ],
        [
         "Somesh",
         88000,
         "Finance",
         22,
         "UP",
         27800
        ],
        [
         "Jennifer",
         59000,
         "Support",
         43,
         "TN",
         35500
        ],
        [
         "Kumar",
         768000,
         "Marketing",
         28,
         "CA",
         945000
        ],
        [
         "Sandya",
         789000,
         "IT",
         37,
         "PNB",
         678900
        ],
        [
         "Swaroop",
         679000,
         "Admin",
         24,
         "KL",
         478000
        ],
        [
         "Joseph",
         789000,
         "Finance",
         29,
         "DL",
         456700
        ],
        [
         "Rashi",
         467800,
         "Maintenance",
         23,
         "TS",
         872300
        ],
        [
         "Krishna",
         945670,
         "Backend",
         39,
         "AP",
         435000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataframe with different order of columns as compared to df1\n",
    "simpleData4 = [(\"Kailash\", 96600, \"Sales\", 30, \"RJ\", 15500), \\\n",
    "               (\"Somesh\", 88000, \"Finance\", 22, \"UP\", 27800), \\\n",
    "               (\"Jennifer\", 59000, \"Support\", 43, \"TN\", 35500), \\\n",
    "               (\"Kumar\", 768000, \"Marketing\", 28, \"CA\", 945000), \\\n",
    "               (\"Sandya\", 789000, \"IT\", 37, \"PNB\", 678900), \\\n",
    "               (\"Swaroop\", 679000, \"Admin\", 24, \"KL\", 478000), \\\n",
    "               (\"Joseph\", 789000, \"Finance\", 29, \"DL\", 456700), \\\n",
    "               (\"Rashi\", 467800, \"Maintenance\", 23, \"TS\", 872300), \\\n",
    "               (\"Krishna\", 945670, \"Backend\", 39, \"AP\", 435000)\n",
    "               ]\n",
    "columns4 = [\"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\"]\n",
    "\n",
    "df4 = spark.createDataFrame(data = simpleData4, schema = columns4)\n",
    "\n",
    "df4.printSchema()\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16e23f8-4428-442f-8f5c-4731e2dcc4be",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dataframe 05"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_name: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- department: string (nullable = true)\n |-- age: long (nullable = true)\n |-- state: string (nullable = true)\n |-- bonus: long (nullable = true)\n |-- pincode: long (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>salary</th><th>department</th><th>age</th><th>state</th><th>bonus</th><th>pincode</th></tr></thead><tbody><tr><td>Kailash</td><td>96600</td><td>Sales</td><td>30</td><td>RJ</td><td>15500</td><td>12345</td></tr><tr><td>Somesh</td><td>88000</td><td>Finance</td><td>22</td><td>UP</td><td>27800</td><td>67890</td></tr><tr><td>Jennifer</td><td>59000</td><td>Support</td><td>43</td><td>TN</td><td>35500</td><td>14789</td></tr><tr><td>Kumar</td><td>768000</td><td>Marketing</td><td>28</td><td>CA</td><td>945000</td><td>98765</td></tr><tr><td>Sandya</td><td>789000</td><td>IT</td><td>37</td><td>PNB</td><td>678900</td><td>85432</td></tr><tr><td>Swaroop</td><td>679000</td><td>Admin</td><td>24</td><td>KL</td><td>478000</td><td>74321</td></tr><tr><td>Joseph</td><td>789000</td><td>Finance</td><td>29</td><td>DL</td><td>456700</td><td>45980</td></tr><tr><td>Rashi</td><td>467800</td><td>Maintenance</td><td>23</td><td>TS</td><td>872300</td><td>517132</td></tr><tr><td>Krishna</td><td>945670</td><td>Backend</td><td>39</td><td>AP</td><td>435000</td><td>560103</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kailash",
         96600,
         "Sales",
         30,
         "RJ",
         15500,
         12345
        ],
        [
         "Somesh",
         88000,
         "Finance",
         22,
         "UP",
         27800,
         67890
        ],
        [
         "Jennifer",
         59000,
         "Support",
         43,
         "TN",
         35500,
         14789
        ],
        [
         "Kumar",
         768000,
         "Marketing",
         28,
         "CA",
         945000,
         98765
        ],
        [
         "Sandya",
         789000,
         "IT",
         37,
         "PNB",
         678900,
         85432
        ],
        [
         "Swaroop",
         679000,
         "Admin",
         24,
         "KL",
         478000,
         74321
        ],
        [
         "Joseph",
         789000,
         "Finance",
         29,
         "DL",
         456700,
         45980
        ],
        [
         "Rashi",
         467800,
         "Maintenance",
         23,
         "TS",
         872300,
         517132
        ],
        [
         "Krishna",
         945670,
         "Backend",
         39,
         "AP",
         435000,
         560103
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "pincode",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataframe with different order of columns and count as compared to df1\n",
    "simpleData5 = [(\"Kailash\", 96600, \"Sales\", 30, \"RJ\", 15500, 12345), \\\n",
    "               (\"Somesh\", 88000, \"Finance\", 22, \"UP\", 27800, 67890), \\\n",
    "               (\"Jennifer\", 59000, \"Support\", 43, \"TN\", 35500, 14789), \\\n",
    "               (\"Kumar\", 768000, \"Marketing\", 28, \"CA\", 945000, 98765), \\\n",
    "               (\"Sandya\", 789000, \"IT\", 37, \"PNB\", 678900, 85432), \\\n",
    "               (\"Swaroop\", 679000, \"Admin\", 24, \"KL\", 478000, 74321), \\\n",
    "               (\"Joseph\", 789000, \"Finance\", 29, \"DL\", 456700, 45980), \\\n",
    "               (\"Rashi\", 467800, \"Maintenance\", 23, \"TS\", 872300, 517132), \\\n",
    "               (\"Krishna\", 945670, \"Backend\", 39, \"AP\", 435000, 560103)\n",
    "               ]\n",
    "columns5 = [\"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\", \"pincode\"]\n",
    "\n",
    "df5 = spark.createDataFrame(data = simpleData5, schema = columns5)\n",
    "\n",
    "df5.printSchema()\n",
    "display(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b6dd6eb-f12e-4e0e-a525-1fb42d9679d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**1) Merge two or more DataFrames using union**\n",
    "- union() method merges **two DataFrames** and returns the new DataFrame with **all rows** from two Dataframes regardless of **duplicate data**.\n",
    "\n",
    "      same column names\n",
    "      same order\n",
    "      same column count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "308e1344-7181-4d33-92d1-935ec2f34840",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "same column names, order and count"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union() to merge two DataFrames has same column names, order and count\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df2: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "unionDF = df1.union(df2)\n",
    "unionDF.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "551f38e1-7ad4-44fc-a12b-f55764d2838c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(unionDF.dropDuplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5b2296-5cbd-467b-9e59-f65790619435",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "rename column of df2"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2_col_re = df2.withColumnRenamed(\"bonus\", \"bonus_new\")\n",
    "display(df2_col_re)\n",
    "unionDFNew = df1.union(df2_col_re)\n",
    "unionDFNew.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3b845d-7776-4324-87be-d3a3a7c2846d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename multiple columns of df2"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2_mltcol_re = df2.withColumnRenamed(\"employee_name\", \"EName\")\\\n",
    "                   .withColumnRenamed(\"department\", \"dept\")\\\n",
    "                   .withColumnRenamed(\"state\", \"country\")\\\n",
    "                   .withColumnRenamed(\"salary\", \"commission\")\\\n",
    "                   .withColumnRenamed(\"bonus_new\", \"age\")\\\n",
    "                   .withColumnRenamed(\"age\", \"bonus\")\n",
    "                   \n",
    "unionDFMult = df1.union(df2_mltcol_re)\n",
    "unionDFMult.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32abe926-5113-4fb9-87fc-3b6d02acd41e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Adding new column to df2"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th><th>hike</th></tr></thead><tbody><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td><td>1550000</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td><td>2780000</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td><td>3550000</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td><td>94500000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td><td>67890000</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td><td>47800000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td><td>45670000</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td><td>87230000</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td><td>43500000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td><td>67890000</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td><td>47800000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500,
         1550000
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800,
         2780000
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500,
         3550000
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000,
         94500000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900,
         67890000
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000,
         47800000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700,
         45670000
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300,
         87230000
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000,
         43500000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900,
         67890000
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000,
         47800000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "hike",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df2.withColumn(\"hike\", df2.bonus*100)\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc4ee71d-83bb-4421-8acb-2fa09b80e030",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "different column count"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3903420035330707>, line 5\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# union() to merge two DataFrames of different count\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1 and df2 has same column names and order but with one extra column in df2\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"pincode\"\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m unionDF1 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munion(df3)\n",
       "\u001B[1;32m      6\u001B[0m unionDF1\u001B[38;5;241m.\u001B[39mdisplay()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4863\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n",
       "\u001B[1;32m   4767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   4768\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing the union of rows in this and another\u001B[39;00m\n",
       "\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   4770\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   4861\u001B[0m \u001B[38;5;124;03m    +---+-----+\u001B[39;00m\n",
       "\u001B[1;32m   4862\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 4863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munion(other\u001B[38;5;241m.\u001B[39m_jdf), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n",
       "'Union false, false\n",
       ":- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n",
       "+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n",
       "   +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n   +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
       },
       "metadata": {
        "errorSummary": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "NUM_COLUMNS_MISMATCH",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42826",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-3903420035330707>, line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# union() to merge two DataFrames of different count\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1 and df2 has same column names and order but with one extra column in df2\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"pincode\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m unionDF1 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munion(df3)\n\u001B[1;32m      6\u001B[0m unionDF1\u001B[38;5;241m.\u001B[39mdisplay()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4863\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m   4767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   4768\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing the union of rows in this and another\u001B[39;00m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   4770\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4861\u001B[0m \u001B[38;5;124;03m    +---+-----+\u001B[39;00m\n\u001B[1;32m   4862\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munion(other\u001B[38;5;241m.\u001B[39m_jdf), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n   +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union() to merge two DataFrames of different count\n",
    "# df1 and df2 has same column names and order but with one extra column in df2\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"pincode\"\n",
    "unionDF1 = df1.union(df3)\n",
    "unionDF1.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd1ae73-2e62-4326-8f6c-7830c523acd9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Remove column \"bonus\""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th></tr></thead><tbody><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df3.select(\"employee_name\", \"department\", \"state\", \"salary\", \"age\")\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f8b33a3-1840-412e-a9c5-95af77b2ad8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2742766298581904>, line 5\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# union() to merge two DataFrames of different count\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1 and df3 has same column names and order but with one less column than df2\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\"\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m unionDF2 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munion(df3)\n",
       "\u001B[1;32m      6\u001B[0m unionDF2\u001B[38;5;241m.\u001B[39mdisplay()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4863\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n",
       "\u001B[1;32m   4767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   4768\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing the union of rows in this and another\u001B[39;00m\n",
       "\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   4770\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   4861\u001B[0m \u001B[38;5;124;03m    +---+-----+\u001B[39;00m\n",
       "\u001B[1;32m   4862\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 4863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munion(other\u001B[38;5;241m.\u001B[39m_jdf), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 5 columns. SQLSTATE: 42826;\n",
       "'Union false, false\n",
       ":- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n",
       "+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L]\n",
       "   +- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n",
       "      +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 5 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L]\n   +- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n      +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
       },
       "metadata": {
        "errorSummary": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 5 columns. SQLSTATE: 42826"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "NUM_COLUMNS_MISMATCH",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42826",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2742766298581904>, line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# union() to merge two DataFrames of different count\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1 and df3 has same column names and order but with one less column than df2\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m unionDF2 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munion(df3)\n\u001B[1;32m      6\u001B[0m unionDF2\u001B[38;5;241m.\u001B[39mdisplay()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4863\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m   4767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   4768\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing the union of rows in this and another\u001B[39;00m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   4770\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4861\u001B[0m \u001B[38;5;124;03m    +---+-----+\u001B[39;00m\n\u001B[1;32m   4862\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munion(other\u001B[38;5;241m.\u001B[39m_jdf), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 5 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#27, department#28, state#29, salary#30L, age#31L]\n   +- Project [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L, (bonus#32L * cast(100 as bigint)) AS hike#268L]\n      +- LogicalRDD [employee_name#27, department#28, state#29, salary#30L, age#31L, bonus#32L], false\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union() to merge two DataFrames of different count\n",
    "# df1 and df3 has same column names and order but with one less column than df2\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df3: \"employee_name\", \"department\", \"state\", \"salary\", \"age\"\n",
    "unionDF2 = df1.union(df3)\n",
    "unionDF2.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "143cad96-1e66-46ab-b9e3-042b89b6d340",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "different order of columns"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>96600</td><td>Sales</td><td>30</td><td>RJ</td><td>15500</td></tr><tr><td>Somesh</td><td>88000</td><td>Finance</td><td>22</td><td>UP</td><td>27800</td></tr><tr><td>Jennifer</td><td>59000</td><td>Support</td><td>43</td><td>TN</td><td>35500</td></tr><tr><td>Kumar</td><td>768000</td><td>Marketing</td><td>28</td><td>CA</td><td>945000</td></tr><tr><td>Sandya</td><td>789000</td><td>IT</td><td>37</td><td>PNB</td><td>678900</td></tr><tr><td>Swaroop</td><td>679000</td><td>Admin</td><td>24</td><td>KL</td><td>478000</td></tr><tr><td>Joseph</td><td>789000</td><td>Finance</td><td>29</td><td>DL</td><td>456700</td></tr><tr><td>Rashi</td><td>467800</td><td>Maintenance</td><td>23</td><td>TS</td><td>872300</td></tr><tr><td>Krishna</td><td>945670</td><td>Backend</td><td>39</td><td>AP</td><td>435000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         "24",
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         "36",
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         "33",
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         "26",
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         "31",
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         "28",
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         "24",
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         "26",
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         "36",
         45000
        ],
        [
         "Kailash",
         "96600",
         "Sales",
         30,
         "RJ",
         15500
        ],
        [
         "Somesh",
         "88000",
         "Finance",
         22,
         "UP",
         27800
        ],
        [
         "Jennifer",
         "59000",
         "Support",
         43,
         "TN",
         35500
        ],
        [
         "Kumar",
         "768000",
         "Marketing",
         28,
         "CA",
         945000
        ],
        [
         "Sandya",
         "789000",
         "IT",
         37,
         "PNB",
         678900
        ],
        [
         "Swaroop",
         "679000",
         "Admin",
         24,
         "KL",
         478000
        ],
        [
         "Joseph",
         "789000",
         "Finance",
         29,
         "DL",
         456700
        ],
        [
         "Rashi",
         "467800",
         "Maintenance",
         23,
         "TS",
         872300
        ],
        [
         "Krishna",
         "945670",
         "Backend",
         39,
         "AP",
         435000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union() to merge two DataFrames of different order of columns\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df4: \"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\"\n",
    "unionDF3 = df1.union(df4)\n",
    "unionDF3.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8c61385-9715-4552-be59-2929eb7c442c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2) Merge DataFrames using unionAll**\n",
    "- DataFrame **unionAll()** method is **deprecated** since **PySpark “2.0.0”** version and recommends using the **union()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d88c1117-2628-40e1-9e32-c17054235eac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "union All"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unionAll() to merge two DataFrames\n",
    "unionAllDF = df1.unionAll(df2)\n",
    "unionAllDF.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e02d7f7f-9f29-483d-8ab6-aed504c772f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Merge without Duplicates**\n",
    "\n",
    "- Since the union() method returns **all rows without distinct records**, we will use the distinct() function to return just one record when a **duplicate exists**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f695a2d-316e-44d4-91f3-cffb7335dcc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove duplicates after union() using distinct()\n",
    "disDF = df1.union(df2).distinct()\n",
    "display(disDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a56dbce-30a1-4312-83ca-cd3c1331b501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3) unionByName**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af01d25-2f8a-433d-87e6-64d2bd8f882a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "unionByName"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same column names, count and order\n",
    "unionByName = df1.unionByName(df2)\n",
    "unionByName.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a66a2548-cb89-4628-8229-1d360287f57c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "unionByName"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_name</th><th>department</th><th>state</th><th>salary</th><th>age</th><th>bonus</th></tr></thead><tbody><tr><td>Kiran</td><td>Sales</td><td>AP</td><td>890000</td><td>24</td><td>35000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Robert</td><td>Marketing</td><td>KA</td><td>567000</td><td>33</td><td>35000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Kamalesh</td><td>IT</td><td>TS</td><td>8946000</td><td>31</td><td>56000</td></tr><tr><td>Mathew</td><td>Maintenance</td><td>KL</td><td>667000</td><td>28</td><td>467000</td></tr><tr><td>Santhosh</td><td>Sales</td><td>MH</td><td>873000</td><td>24</td><td>734000</td></tr><tr><td>Swetha</td><td>Finance</td><td>PNB</td><td>598000</td><td>26</td><td>99000</td></tr><tr><td>Mohan</td><td>Admin</td><td>TN</td><td>756000</td><td>36</td><td>45000</td></tr><tr><td>Kailash</td><td>Sales</td><td>RJ</td><td>96600</td><td>30</td><td>15500</td></tr><tr><td>Somesh</td><td>Finance</td><td>UP</td><td>88000</td><td>22</td><td>27800</td></tr><tr><td>Jennifer</td><td>Support</td><td>TN</td><td>59000</td><td>43</td><td>35500</td></tr><tr><td>Kumar</td><td>Marketing</td><td>CA</td><td>768000</td><td>28</td><td>945000</td></tr><tr><td>Sandya</td><td>IT</td><td>PNB</td><td>789000</td><td>37</td><td>678900</td></tr><tr><td>Swaroop</td><td>Admin</td><td>KL</td><td>679000</td><td>24</td><td>478000</td></tr><tr><td>Joseph</td><td>Finance</td><td>DL</td><td>789000</td><td>29</td><td>456700</td></tr><tr><td>Rashi</td><td>Maintenance</td><td>TS</td><td>467800</td><td>23</td><td>872300</td></tr><tr><td>Krishna</td><td>Backend</td><td>AP</td><td>945670</td><td>39</td><td>435000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Kiran",
         "Sales",
         "AP",
         890000,
         24,
         35000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Robert",
         "Marketing",
         "KA",
         567000,
         33,
         35000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Kamalesh",
         "IT",
         "TS",
         8946000,
         31,
         56000
        ],
        [
         "Mathew",
         "Maintenance",
         "KL",
         667000,
         28,
         467000
        ],
        [
         "Santhosh",
         "Sales",
         "MH",
         873000,
         24,
         734000
        ],
        [
         "Swetha",
         "Finance",
         "PNB",
         598000,
         26,
         99000
        ],
        [
         "Mohan",
         "Admin",
         "TN",
         756000,
         36,
         45000
        ],
        [
         "Kailash",
         "Sales",
         "RJ",
         96600,
         30,
         15500
        ],
        [
         "Somesh",
         "Finance",
         "UP",
         88000,
         22,
         27800
        ],
        [
         "Jennifer",
         "Support",
         "TN",
         59000,
         43,
         35500
        ],
        [
         "Kumar",
         "Marketing",
         "CA",
         768000,
         28,
         945000
        ],
        [
         "Sandya",
         "IT",
         "PNB",
         789000,
         37,
         678900
        ],
        [
         "Swaroop",
         "Admin",
         "KL",
         679000,
         24,
         478000
        ],
        [
         "Joseph",
         "Finance",
         "DL",
         789000,
         29,
         456700
        ],
        [
         "Rashi",
         "Maintenance",
         "TS",
         467800,
         23,
         872300
        ],
        [
         "Krishna",
         "Backend",
         "AP",
         945670,
         39,
         435000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unionByName to merge two DataFrames has same column count and different order of columns\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df4: \"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\"\n",
    "unionByName1 = df1.unionByName(df4)\n",
    "unionByName1.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b95e3e4f-cc13-4ecc-a5ac-88e39c9e66fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "unionByName"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3903420035330711>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# unionByName to merge two DataFrames has different column count and different order of columns\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df5: \"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\", \"pincode\"\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m unionByName2 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munionByName(df5)\n",
       "\u001B[1;32m      5\u001B[0m unionByName2\u001B[38;5;241m.\u001B[39mdisplay()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4977\u001B[0m, in \u001B[0;36mDataFrame.unionByName\u001B[0;34m(self, other, allowMissingColumns)\u001B[0m\n",
       "\u001B[1;32m   4899\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munionByName\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, allowMissingColumns: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   4900\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n",
       "\u001B[1;32m   4901\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   4902\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   4975\u001B[0m \u001B[38;5;124;03m    +----+----+----+----+----+----+\u001B[39;00m\n",
       "\u001B[1;32m   4976\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 4977\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munionByName(other\u001B[38;5;241m.\u001B[39m_jdf, allowMissingColumns), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n",
       "'Union false, false\n",
       ":- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n",
       "+- Project [employee_name#77, department#79, state#81, salary#78L, age#80L, bonus#82L, pincode#83L]\n",
       "   +- LogicalRDD [employee_name#77, salary#78L, department#79, age#80L, state#81, bonus#82L, pincode#83L], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#77, department#79, state#81, salary#78L, age#80L, bonus#82L, pincode#83L]\n   +- LogicalRDD [employee_name#77, salary#78L, department#79, age#80L, state#81, bonus#82L, pincode#83L], false\n"
       },
       "metadata": {
        "errorSummary": "[NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "NUM_COLUMNS_MISMATCH",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42826",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-3903420035330711>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# unionByName to merge two DataFrames has different column count and different order of columns\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# df5: \"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\", \"pincode\"\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m unionByName2 \u001B[38;5;241m=\u001B[39m df1\u001B[38;5;241m.\u001B[39munionByName(df5)\n\u001B[1;32m      5\u001B[0m unionByName2\u001B[38;5;241m.\u001B[39mdisplay()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:4977\u001B[0m, in \u001B[0;36mDataFrame.unionByName\u001B[0;34m(self, other, allowMissingColumns)\u001B[0m\n\u001B[1;32m   4899\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munionByName\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, allowMissingColumns: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   4900\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n\u001B[1;32m   4901\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   4902\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4975\u001B[0m \u001B[38;5;124;03m    +----+----+----+----+----+----+\u001B[39;00m\n\u001B[1;32m   4976\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4977\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39munionByName(other\u001B[38;5;241m.\u001B[39m_jdf, allowMissingColumns), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 6 columns and the second input has 7 columns. SQLSTATE: 42826;\n'Union false, false\n:- LogicalRDD [employee_name#2, department#3, state#4, salary#5L, age#6L, bonus#7L], false\n+- Project [employee_name#77, department#79, state#81, salary#78L, age#80L, bonus#82L, pincode#83L]\n   +- LogicalRDD [employee_name#77, salary#78L, department#79, age#80L, state#81, bonus#82L, pincode#83L], false\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unionByName to merge two DataFrames has different column count and different order of columns\n",
    "# df1: \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"\n",
    "# df5: \"employee_name\", \"salary\", \"department\", \"age\", \"state\", \"bonus\", \"pincode\"\n",
    "unionByName2 = df1.unionByName(df5)\n",
    "unionByName2.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "83_union(), unionAll() & unionbyname",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
