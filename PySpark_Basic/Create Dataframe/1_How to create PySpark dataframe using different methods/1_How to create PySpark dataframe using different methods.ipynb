{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90e47553-5df1-4b99-8357-c24c629945a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Topics covered**\n",
    "\n",
    "     1) Create a DataFrame from a List of Tuples\n",
    "     2) Create a DataFrame from a List of Lists\n",
    "     3) Create a DataFrame using dictionary\n",
    "     4) Create a DataFrame from a Simple List\n",
    "     5) Create a DataFrame with an Explicit Schema\n",
    "     6) Create a DataFrame Directly from a List Using Row\n",
    "     7) toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae034b7-5098-415f-bec3-af3b8181fb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method createDataFrame in module pyspark.sql.session:\n\ncreateDataFrame(data: Union[ForwardRef('RDD[Any]'), Iterable[Any], ForwardRef('PandasDataFrameLike'), ForwardRef('ArrayLike')], schema: Union[pyspark.sql.types.AtomicType, pyspark.sql.types.StructType, str, NoneType] = None, samplingRatio: Optional[float] = None, verifySchema: bool = True) -> pyspark.sql.dataframe.DataFrame method of pyspark.sql.session.SparkSession instance\n    Creates a :class:`DataFrame` from an :class:`RDD`, a list, a :class:`pandas.DataFrame`\n    or a :class:`numpy.ndarray`.\n    \n    .. versionadded:: 2.0.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    data : :class:`RDD` or iterable\n        an RDD of any kind of SQL data representation (:class:`Row`,\n        :class:`tuple`, ``int``, ``boolean``, ``dict``, etc.), or :class:`list`,\n        :class:`pandas.DataFrame` or :class:`numpy.ndarray`.\n    schema : :class:`pyspark.sql.types.DataType`, str or list, optional\n        a :class:`pyspark.sql.types.DataType` or a datatype string or a list of\n        column names, default is None. The data type string format equals to\n        :class:`pyspark.sql.types.DataType.simpleString`, except that top level struct type can\n        omit the ``struct<>``.\n    \n        When ``schema`` is a list of column names, the type of each column\n        will be inferred from ``data``.\n    \n        When ``schema`` is ``None``, it will try to infer the schema (column names and types)\n        from ``data``, which should be an RDD of either :class:`Row`,\n        :class:`namedtuple`, or :class:`dict`.\n    \n        When ``schema`` is :class:`pyspark.sql.types.DataType` or a datatype string, it must\n        match the real data, or an exception will be thrown at runtime. If the given schema is\n        not :class:`pyspark.sql.types.StructType`, it will be wrapped into a\n        :class:`pyspark.sql.types.StructType` as its only field, and the field name will be\n        \"value\". Each record will also be wrapped into a tuple, which can be converted to row\n        later.\n    samplingRatio : float, optional\n        the sample ratio of rows used for inferring. The first few rows will be used\n        if ``samplingRatio`` is ``None``. This option is effective only when the input is\n        :class:`RDD`.\n    verifySchema : bool, optional\n        verify data types of every row against schema. Enabled by default.\n        When the input is :class:`pandas.DataFrame` and\n        `spark.sql.execution.arrow.pyspark.enabled` is enabled, this option is not\n        effective. It follows Arrow type coercion. This option is not supported with\n        Spark Connect.\n    \n        .. versionadded:: 2.1.0\n    \n    Returns\n    -------\n    :class:`DataFrame`\n    \n    Notes\n    -----\n    Usage with `spark.sql.execution.arrow.pyspark.enabled=True` is experimental.\n    \n    Examples\n    --------\n    Create a DataFrame from a list of tuples.\n    \n    >>> spark.createDataFrame([('Alice', 1)]).show()\n    +-----+---+\n    |   _1| _2|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    \n    Create a DataFrame from a list of dictionaries.\n    \n    >>> d = [{'name': 'Alice', 'age': 1}]\n    >>> spark.createDataFrame(d).show()\n    +---+-----+\n    |age| name|\n    +---+-----+\n    |  1|Alice|\n    +---+-----+\n    \n    Create a DataFrame with column names specified.\n    \n    >>> spark.createDataFrame([('Alice', 1)], ['name', 'age']).show()\n    +-----+---+\n    | name|age|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    \n    Create a DataFrame with the explicit schema specified.\n    \n    >>> from pyspark.sql.types import *\n    >>> schema = StructType([\n    ...    StructField(\"name\", StringType(), True),\n    ...    StructField(\"age\", IntegerType(), True)])\n    >>> spark.createDataFrame([('Alice', 1)], schema).show()\n    +-----+---+\n    | name|age|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    \n    Create a DataFrame with the schema in DDL formatted string.\n    \n    >>> spark.createDataFrame([('Alice', 1)], \"name: string, age: int\").show()\n    +-----+---+\n    | name|age|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    \n    Create an empty DataFrame.\n    When initializing an empty DataFrame in PySpark, it's mandatory to specify its schema,\n    as the DataFrame lacks data from which the schema can be inferred.\n    \n    >>> spark.createDataFrame([], \"name: string, age: int\").show()\n    +----+---+\n    |name|age|\n    +----+---+\n    +----+---+\n    \n    Create a DataFrame from Row objects.\n    \n    >>> from pyspark.sql import Row\n    >>> Person = Row('name', 'age')\n    >>> df = spark.createDataFrame([Person(\"Alice\", 1)])\n    >>> df.show()\n    +-----+---+\n    | name|age|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    \n    Create a DataFrame from a pandas DataFrame.\n    \n    >>> spark.createDataFrame(df.toPandas()).show()  # doctest: +SKIP\n    +-----+---+\n    | name|age|\n    +-----+---+\n    |Alice|  1|\n    +-----+---+\n    >>> spark.createDataFrame(pandas.DataFrame([[1, 2]])).collect()  # doctest: +SKIP\n    +---+---+\n    |  0|  1|\n    +---+---+\n    |  1|  2|\n    +---+---+\n\n"
     ]
    }
   ],
   "source": [
    "help(spark.createDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2ef120-e8a3-4433-8a95-08291f920130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**1) Create a DataFrame from a List of Tuples**\n",
    "- If your **list** contains **tuples** where **each tuple represents a row**, you can create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956e9773-6227-489d-9f03-3c4b1e690397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of tuples\n",
    "data = [(1, \"Albert\", 25, \"Sales\", \"ADF\"),\n",
    "        (2, \"Buvan\", 30, \"Marketing\", \"Oracle\"),\n",
    "        (3, \"Chandar\", 28, \"IT\", \"SAP\"),\n",
    "        (4, \"Syam\", 33, \"Admin\", \"Tally\"),\n",
    "        (5, \"Senthil\", 26, \"Production\", \"MATLAB\"),\n",
    "        (6, \"Surya\", 35, \"Quality\", \"Excel\")]\n",
    "\n",
    "# Define column names\n",
    "columns = [\"ID\", \"Name\", \"Age\", \"Department\", \"Technology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a3a4b18-171b-4c47-a5e4-f828405cfd72",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Technology</th></tr></thead><tbody><tr><td>1</td><td>Albert</td><td>25</td><td>Sales</td><td>ADF</td></tr><tr><td>2</td><td>Buvan</td><td>30</td><td>Marketing</td><td>Oracle</td></tr><tr><td>3</td><td>Chandar</td><td>28</td><td>IT</td><td>SAP</td></tr><tr><td>4</td><td>Syam</td><td>33</td><td>Admin</td><td>Tally</td></tr><tr><td>5</td><td>Senthil</td><td>26</td><td>Production</td><td>MATLAB</td></tr><tr><td>6</td><td>Surya</td><td>35</td><td>Quality</td><td>Excel</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Albert",
         25,
         "Sales",
         "ADF"
        ],
        [
         2,
         "Buvan",
         30,
         "Marketing",
         "Oracle"
        ],
        [
         3,
         "Chandar",
         28,
         "IT",
         "SAP"
        ],
        [
         4,
         "Syam",
         33,
         "Admin",
         "Tally"
        ],
        [
         5,
         "Senthil",
         26,
         "Production",
         "MATLAB"
        ],
        [
         6,
         "Surya",
         35,
         "Quality",
         "Excel"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Display DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52f8b9c0-b015-4f87-ab2c-97508de93063",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Technology</th></tr></thead><tbody><tr><td>1</td><td>Albert</td><td>25</td><td>Sales</td><td>ADF</td></tr><tr><td>2</td><td>Buvan</td><td>30</td><td>Marketing</td><td>Oracle</td></tr><tr><td>3</td><td>Chandar</td><td>28</td><td>IT</td><td>SAP</td></tr><tr><td>4</td><td>Syam</td><td>33</td><td>Admin</td><td>Tally</td></tr><tr><td>5</td><td>Senthil</td><td>26</td><td>Production</td><td>MATLAB</td></tr><tr><td>6</td><td>Surya</td><td>35</td><td>Quality</td><td>Excel</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Albert",
         25,
         "Sales",
         "ADF"
        ],
        [
         2,
         "Buvan",
         30,
         "Marketing",
         "Oracle"
        ],
        [
         3,
         "Chandar",
         28,
         "IT",
         "SAP"
        ],
        [
         4,
         "Syam",
         33,
         "Admin",
         "Tally"
        ],
        [
         5,
         "Senthil",
         26,
         "Production",
         "MATLAB"
        ],
        [
         6,
         "Surya",
         35,
         "Quality",
         "Excel"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df1 = spark.createDataFrame(data, 'ID int, Name string, Age int, Department string, Technology string')\n",
    "\n",
    "# Display DataFrame\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab763404-c364-4b27-b77e-db7f5ce36688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2) Create a DataFrame from a List of Lists**\n",
    "- If your **list** contains **lists instead of tuples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bad41f4-8ddc-4454-b9fa-d9401eef2e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Technology</th></tr></thead><tbody><tr><td>1</td><td>Albert</td><td>25</td><td>Sales</td><td>ADF</td></tr><tr><td>2</td><td>Buvan</td><td>30</td><td>Marketing</td><td>Oracle</td></tr><tr><td>3</td><td>Chandar</td><td>28</td><td>IT</td><td>SAP</td></tr><tr><td>4</td><td>Syam</td><td>33</td><td>Admin</td><td>Tally</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Albert",
         25,
         "Sales",
         "ADF"
        ],
        [
         2,
         "Buvan",
         30,
         "Marketing",
         "Oracle"
        ],
        [
         3,
         "Chandar",
         28,
         "IT",
         "SAP"
        ],
        [
         4,
         "Syam",
         33,
         "Admin",
         "Tally"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of Lists\n",
    "data = [[1, \"Albert\", 25, \"Sales\", \"ADF\"],\n",
    "        [2, \"Buvan\", 30, \"Marketing\", \"Oracle\"],\n",
    "        [3, \"Chandar\", 28, \"IT\", \"SAP\"],\n",
    "        [4, \"Syam\", 33, \"Admin\", \"Tally\"]]\n",
    "\n",
    "# Define column names\n",
    "columns = [\"ID\", \"Name\", \"Age\", \"Department\", \"Technology\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data, schema=columns)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "433183c9-ec34-405d-ba6c-272292abaf0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3) Create a DataFrame using dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a10f439-115d-4b56-84d5-76b88e00959e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Country</th><th>ID</th><th>Name</th></tr></thead><tbody><tr><td>USA</td><td>A123</td><td>Jayanth</td></tr><tr><td>USA</td><td>A124</td><td>Rupesh</td></tr><tr><td>IND</td><td>A125</td><td>Thrusanth</td></tr><tr><td>USA</td><td>A126</td><td>Jahangeer</td></tr><tr><td>INA</td><td>A127</td><td>Sowmya</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "USA",
         "A123",
         "Jayanth"
        ],
        [
         "USA",
         "A124",
         "Rupesh"
        ],
        [
         "IND",
         "A125",
         "Thrusanth"
        ],
        [
         "USA",
         "A126",
         "Jahangeer"
        ],
        [
         "INA",
         "A127",
         "Sowmya"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [{'Name':'Jayanth', 'ID':'A123', 'Country':'USA'},\n",
    "        {'Name':'Rupesh', 'ID':'A124', 'Country':'USA'},\n",
    "        {'Name':'Thrusanth', 'ID':'A125', 'Country':'IND'},\n",
    "        {'Name':'Jahangeer', 'ID':'A126', 'Country':'USA'},\n",
    "        {'Name':'Sowmya', 'ID':'A127', 'Country':'INA'}]\n",
    "\n",
    "df_dict = spark.createDataFrame(data)\n",
    "display(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4134c3ec-21d0-4018-89cd-cc53c4838896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**4) Create a DataFrame from a Simple List**\n",
    "- If your **list** contains a **single column**, you can still use createDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1305c32-120d-4a78-891b-378662249009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     # Method 01\n",
    "     df = spark.createDataFrame(data, 'int')\n",
    "\n",
    "     # Method 02\n",
    "     df = spark.createDataFrame([(x,) for x in data], [\"Numbers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ea72647-64de-467b-8ac0-db8edb08ed67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>value</th></tr></thead><tbody><tr><td>15</td></tr><tr><td>25</td></tr><tr><td>36</td></tr><tr><td>44</td></tr><tr><td>57</td></tr><tr><td>65</td></tr><tr><td>89</td></tr><tr><td>95</td></tr><tr><td>9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         15
        ],
        [
         25
        ],
        [
         36
        ],
        [
         44
        ],
        [
         57
        ],
        [
         65
        ],
        [
         89
        ],
        [
         95
        ],
        [
         9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [15, 25, 36, 44, 57, 65, 89, 95, 9]\n",
    "\n",
    "df3 = spark.createDataFrame(data, 'int')\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff26814-e9b2-4ea1-8840-a4604f9b51d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Numbers</th></tr></thead><tbody><tr><td>15</td></tr><tr><td>25</td></tr><tr><td>36</td></tr><tr><td>44</td></tr><tr><td>57</td></tr><tr><td>65</td></tr><tr><td>89</td></tr><tr><td>95</td></tr><tr><td>9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         15
        ],
        [
         25
        ],
        [
         36
        ],
        [
         44
        ],
        [
         57
        ],
        [
         65
        ],
        [
         89
        ],
        [
         95
        ],
        [
         9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Numbers",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df3.withColumnRenamed(\"value\", \"Numbers\")\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b09d10e-5252-4b7b-8453-6bb4307c7cbf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Numbers</th></tr></thead><tbody><tr><td>15</td></tr><tr><td>25</td></tr><tr><td>36</td></tr><tr><td>44</td></tr><tr><td>57</td></tr><tr><td>65</td></tr><tr><td>89</td></tr><tr><td>95</td></tr><tr><td>9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         15
        ],
        [
         25
        ],
        [
         36
        ],
        [
         44
        ],
        [
         57
        ],
        [
         65
        ],
        [
         89
        ],
        [
         95
        ],
        [
         9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Numbers",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [15, 25, 36, 44, 57, 65, 89, 95, 9]\n",
    "\n",
    "df4 = spark.createDataFrame([(x,) for x in data], [\"Numbers\"])\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17c41bbb-6a0d-4ede-baf3-abe6de43fd8e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 03"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>5</td></tr><tr><td>6</td></tr><tr><td>7</td></tr><tr><td>8</td></tr><tr><td>9</td></tr><tr><td>10</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         4
        ],
        [
         5
        ],
        [
         6
        ],
        [
         7
        ],
        [
         8
        ],
        [
         9
        ],
        [
         10
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [(1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,)]\n",
    "\n",
    "df41 = spark.createDataFrame(data, [\"id\"])\n",
    "display(df41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad62121d-fdc6-48af-ab59-8fb78b8f823d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**5) Create a DataFrame with an Explicit Schema**\n",
    "- You can define the **schema** explicitly using **StructType and StructField**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4cf3f6-4c09-4b50-b892-115fe353745c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 01"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Technology</th></tr></thead><tbody><tr><td>1</td><td>Albert</td><td>25</td><td>Sales</td><td>ADF</td></tr><tr><td>2</td><td>Buvan</td><td>30</td><td>Marketing</td><td>Oracle</td></tr><tr><td>3</td><td>Chandar</td><td>28</td><td>IT</td><td>SAP</td></tr><tr><td>4</td><td>Syam</td><td>33</td><td>Admin</td><td>Tally</td></tr><tr><td>5</td><td>Bharat</td><td>28</td><td>Maintenance</td><td>Excel</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Albert",
         25,
         "Sales",
         "ADF"
        ],
        [
         2,
         "Buvan",
         30,
         "Marketing",
         "Oracle"
        ],
        [
         3,
         "Chandar",
         28,
         "IT",
         "SAP"
        ],
        [
         4,
         "Syam",
         33,
         "Admin",
         "Tally"
        ],
        [
         5,
         "Bharat",
         28,
         "Maintenance",
         "Excel"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "data = [[1, \"Albert\", 25, \"Sales\", \"ADF\"],\n",
    "        [2, \"Buvan\", 30, \"Marketing\", \"Oracle\"],\n",
    "        [3, \"Chandar\", 28, \"IT\", \"SAP\"],\n",
    "        [4, \"Syam\", 33, \"Admin\", \"Tally\"],\n",
    "        [5, \"Bharat\", 28, \"Maintenance\", \"Excel\"]]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Technology\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_schema = spark.createDataFrame(data, schema=schema)\n",
    "display(df_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e24a3093-5afe-4d92-8788-47409f06b936",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 02"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>rollno</th><th>name</th><th>age</th><th>height</th><th>weight</th><th>address</th></tr></thead><tbody><tr><td>001</td><td>sravan</td><td>23</td><td>5.79</td><td>67</td><td>Chennai</td></tr><tr><td>002</td><td>ojaswi</td><td>16</td><td>3.79</td><td>34</td><td>Hyderabad</td></tr><tr><td>003</td><td>gnanesh chowdary</td><td>7</td><td>2.79</td><td>17</td><td>Bangalore</td></tr><tr><td>004</td><td>rohith</td><td>9</td><td>3.69</td><td>28</td><td>Delhi</td></tr><tr><td>005</td><td>sridevi</td><td>37</td><td>5.59</td><td>54</td><td>Nasik</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "001",
         "sravan",
         23,
         5.79,
         67,
         "Chennai"
        ],
        [
         "002",
         "ojaswi",
         16,
         3.79,
         34,
         "Hyderabad"
        ],
        [
         "003",
         "gnanesh chowdary",
         7,
         2.79,
         17,
         "Bangalore"
        ],
        [
         "004",
         "rohith",
         9,
         3.69,
         28,
         "Delhi"
        ],
        [
         "005",
         "sridevi",
         37,
         5.59,
         54,
         "Nasik"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "rollno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "height",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "weight",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "address",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create student data with 5 rows and 6 attributes\n",
    "students =[['001', 'sravan', 23, 5.79, 67, 'Chennai'],\n",
    "            ['002', 'ojaswi', 16, 3.79, 34, 'Hyderabad'],\n",
    "            ['003', 'gnanesh chowdary', 7, 2.79, 17, 'Bangalore'],\n",
    "            ['004', 'rohith', 9, 3.69, 28, 'Delhi'],\n",
    "            ['005', 'sridevi', 37, 5.59, 54, 'Nasik']]\n",
    "\n",
    "# define the StructType and StructFields for the below column names\n",
    "schema = \"\"\"rollno string, name string, age int, height float, weight int, address string\"\"\"\n",
    "\n",
    "# create the dataframe and add schema to the dataframe\n",
    "df_schema_string = spark.createDataFrame(students, schema=schema)\n",
    "display(df_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0395a660-8e87-41fd-a151-4949ff533125",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Method 03"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Marks</th></tr></thead><tbody><tr><td>1</td><td>Sandhya</td><td>List(20, 30, 40)</td></tr><tr><td>2</td><td>Alex</td><td>List(40, 20, 10)</td></tr><tr><td>3</td><td>Joseph</td><td>List()</td></tr><tr><td>4</td><td>Arya</td><td>List(20, 1, null)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Sandhya",
         [
          20,
          30,
          40
         ]
        ],
        [
         2,
         "Alex",
         [
          40,
          20,
          10
         ]
        ],
        [
         3,
         "Joseph",
         []
        ],
        [
         4,
         "Arya",
         [
          20,
          1,
          null
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Marks",
         "type": "{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(1, 'Sandhya', [20, 30, 40]),\n",
    "        (2, 'Alex', [40, 20, 10]),\n",
    "        (3, 'Joseph', []),\n",
    "        (4, 'Arya', [20, 1, None])]\n",
    "\n",
    "df_schema_def = spark.createDataFrame(data, schema=\"ID int, Name string, Marks array<int>\")\n",
    "display(df_schema_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62aeff09-5ba5-415f-956e-da6b0a0f93a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**6) Create a DataFrame Directly from a List Using Row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02a79c7e-4395-4b68-bf14-1e2220eeced2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Name</th><th>Age</th><th>Department</th><th>Technology</th></tr></thead><tbody><tr><td>1</td><td>Albert</td><td>25</td><td>Sales</td><td>ADF</td></tr><tr><td>2</td><td>Buvan</td><td>30</td><td>Marketing</td><td>Oracle</td></tr><tr><td>3</td><td>Chandar</td><td>28</td><td>IT</td><td>SAP</td></tr><tr><td>4</td><td>Syam</td><td>33</td><td>Admin</td><td>Tally</td></tr><tr><td>5</td><td>Bharat</td><td>28</td><td>Maintenance</td><td>Excel</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Albert",
         25,
         "Sales",
         "ADF"
        ],
        [
         2,
         "Buvan",
         30,
         "Marketing",
         "Oracle"
        ],
        [
         3,
         "Chandar",
         28,
         "IT",
         "SAP"
        ],
        [
         4,
         "Syam",
         33,
         "Admin",
         "Tally"
        ],
        [
         5,
         "Bharat",
         28,
         "Maintenance",
         "Excel"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Technology",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [Row(ID=1, Name=\"Albert\", Age=25, Department=\"Sales\", Technology=\"ADF\"),\n",
    "        Row(ID=2, Name=\"Buvan\", Age=30, Department=\"Marketing\", Technology=\"Oracle\"),\n",
    "        Row(ID=3, Name=\"Chandar\", Age=28, Department=\"IT\", Technology=\"SAP\"),\n",
    "        Row(ID=4, Name=\"Syam\", Age=33, Department=\"Admin\", Technology=\"Tally\"),\n",
    "        Row(ID=5, Name=\"Bharat\", Age=28, Department=\"Maintenance\", Technology=\"Excel\")]\n",
    "\n",
    "df_row = spark.createDataFrame(data)\n",
    "display(df_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ccb0037-ffa9-4a4d-9f12-5fa0a789018b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**7) toDF()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf32258b-a354-498a-8306-0abf99f94597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_id</th><th>first_name</th><th>last_name</th><th>salary</th><th>nationality</th><th>phone_number</th><th>ssn</th></tr></thead><tbody><tr><td>1</td><td>Santhosh</td><td>Kumar</td><td>1000.0</td><td>united states</td><td>+1 123 456 7890</td><td>123 45 6789</td></tr><tr><td>2</td><td>Hemanth</td><td>Raju</td><td>1250.0</td><td>India</td><td>+91 234 567 8901</td><td>456 78 9123</td></tr><tr><td>3</td><td>Nisha</td><td>Kakkar</td><td>750.0</td><td>united KINGDOM</td><td>+44 111 111 1111</td><td>222 33 4444</td></tr><tr><td>4</td><td>Bobby</td><td>Deol</td><td>1500.0</td><td>AUSTRALIA</td><td>+61 987 654 3210</td><td>789 12 6118</td></tr><tr><td>5</td><td>Harish</td><td>Rao</td><td>1650.0</td><td>Sweden</td><td>+91 234 567 8901</td><td>456 78 9123</td></tr><tr><td>6</td><td>Yung</td><td>Lee</td><td>850.0</td><td>China</td><td>+44 222 111 1111</td><td>567 33 4444</td></tr><tr><td>7</td><td>Bushan</td><td>Dayal</td><td>1770.0</td><td>Butan</td><td>+71 932 654 5215</td><td>489 16 8318</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Santhosh",
         "Kumar",
         1000.0,
         "united states",
         "+1 123 456 7890",
         "123 45 6789"
        ],
        [
         2,
         "Hemanth",
         "Raju",
         1250.0,
         "India",
         "+91 234 567 8901",
         "456 78 9123"
        ],
        [
         3,
         "Nisha",
         "Kakkar",
         750.0,
         "united KINGDOM",
         "+44 111 111 1111",
         "222 33 4444"
        ],
        [
         4,
         "Bobby",
         "Deol",
         1500.0,
         "AUSTRALIA",
         "+61 987 654 3210",
         "789 12 6118"
        ],
        [
         5,
         "Harish",
         "Rao",
         1650.0,
         "Sweden",
         "+91 234 567 8901",
         "456 78 9123"
        ],
        [
         6,
         "Yung",
         "Lee",
         850.0,
         "China",
         "+44 222 111 1111",
         "567 33 4444"
        ],
        [
         7,
         "Bushan",
         "Dayal",
         1770.0,
         "Butan",
         "+71 932 654 5215",
         "489 16 8318"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "nationality",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "phone_number",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ssn",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "employees = [(1, \"Santhosh\", \"Kumar\", 1000.0, \"united states\", \"+1 123 456 7890\", \"123 45 6789\"),\n",
    "             (2, \"Hemanth\", \"Raju\", 1250.0, \"India\", \"+91 234 567 8901\", \"456 78 9123\"),\n",
    "             (3, \"Nisha\", \"Kakkar\", 750.0, \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"),\n",
    "             (4, \"Bobby\", \"Deol\", 1500.0, \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"),\n",
    "             (5, \"Harish\", \"Rao\", 1650.0, \"Sweden\", \"+91 234 567 8901\", \"456 78 9123\"),\n",
    "             (6, \"Yung\", \"Lee\", 850.0, \"China\", \"+44 222 111 1111\", \"567 33 4444\"),\n",
    "             (7, \"Bushan\", \"Dayal\", 1770.0, \"Butan\", \"+71 932 654 5215\", \"489 16 8318\")]\n",
    "\n",
    "# create the dataframe\n",
    "df_todf = spark.createDataFrame(employees). \\\n",
    "     toDF(\"employee_id\", \"first_name\", \"last_name\", \"salary\", \"nationality\", \"phone_number\", \"ssn\")\n",
    "display(df_todf)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_How to create PySpark dataframe using different methods",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}