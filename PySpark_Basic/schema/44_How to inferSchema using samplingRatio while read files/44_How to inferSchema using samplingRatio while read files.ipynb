{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cdfeebb-ce8e-46fa-a159-2482ccb5aa36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### What is .option(\"samplingRatio\", value)?\n",
    "\n",
    "- When you use **inferSchema=True**, Spark **scans** your dataset to **guess data types**.\n",
    "- But scanning the **entire file** can be **slow for large datasets**.\n",
    "- By default, Spark **samples the first 1000 rows** to **infer the schema**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cbf25b5-8732-4b4d-b0a1-dcfe73f87854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Syntax\n",
    "\n",
    "     .option(\"samplingRatio\", <value between 0.0 and 1.0>)\n",
    "\n",
    "- **0.1** → use **10% of rows** for schema inference.\n",
    "- **1.0** → use **100%** (default, full scan)\n",
    "- **0.01** → use only **1% of rows**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b3c24fc-84a3-481b-8210-c27700ecd8f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "       .option(\"samplingRatio\", 0.1)\n",
    "\n",
    "- This tells Spark to **sample 10% of the rows**. A **higher ratio** means **more accuracy** but **longer loading time**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a75f725e-95a6-403d-8d01-ab20a30d1f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### 1) For CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae256c19-660b-4e3d-878f-fbede4c5ace4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### a) Default behavior / Full inference (no samplingRatio)\n",
    "- Spark reads **all rows** to infer schema.\n",
    "- **Most accurate**, but **slow for large data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58d6944d-3055-4fc5-8380-059392dafde1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th><th>salry</th></tr></thead><tbody><tr><td>1</td><td>Jyoti</td><td>25</td><td>50000</td></tr><tr><td>2</td><td>Albert</td><td>30</td><td>60000</td></tr><tr><td>3</td><td>Baby</td><td>35</td><td>55000</td></tr><tr><td>4</td><td>Chethan</td><td>40</td><td>70000</td></tr><tr><td>5</td><td>David</td><td>45</td><td>45000</td></tr><tr><td>6</td><td>Elango</td><td>50</td><td>25000</td></tr><tr><td>7</td><td>Firoj</td><td>55</td><td>15000</td></tr><tr><td>8</td><td>Giri</td><td>60</td><td>28000</td></tr><tr><td>9</td><td>Hemanth</td><td>65</td><td>38000</td></tr><tr><td>10</td><td>Indra</td><td>70</td><td>43000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Jyoti",
         25,
         50000
        ],
        [
         2,
         "Albert",
         30,
         60000
        ],
        [
         3,
         "Baby",
         35,
         55000
        ],
        [
         4,
         "Chethan",
         40,
         70000
        ],
        [
         5,
         "David",
         45,
         45000
        ],
        [
         6,
         "Elango",
         50,
         25000
        ],
        [
         7,
         "Firoj",
         55,
         15000
        ],
        [
         8,
         "Giri",
         60,
         28000
        ],
        [
         9,
         "Hemanth",
         65,
         38000
        ],
        [
         10,
         "Indra",
         70,
         43000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salry",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_def = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/Volumes/@azureadb/pyspark/dataframe/inferschema.csv\")\n",
    "display(df_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42de7450-926c-4b47-903c-971adcb54cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### b) Use samplingRatio=0.1 (10%)\n",
    "- Spark reads only **10% of rows** & Guesses schema from that sample.\n",
    "- **Much faster** schema inference (especially if file is **very large**)\n",
    "- Slightly **higher chance** of **incorrect data types**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb46f178-f82e-4030-a28f-194c39612298",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th><th>salry</th></tr></thead><tbody><tr><td>1</td><td>Jyoti</td><td>25</td><td>50000</td></tr><tr><td>2</td><td>Albert</td><td>30</td><td>60000</td></tr><tr><td>3</td><td>Baby</td><td>35</td><td>55000</td></tr><tr><td>4</td><td>Chethan</td><td>40</td><td>70000</td></tr><tr><td>5</td><td>David</td><td>45</td><td>45000</td></tr><tr><td>6</td><td>Elango</td><td>50</td><td>25000</td></tr><tr><td>7</td><td>Firoj</td><td>55</td><td>15000</td></tr><tr><td>8</td><td>Giri</td><td>60</td><td>28000</td></tr><tr><td>9</td><td>Hemanth</td><td>65</td><td>38000</td></tr><tr><td>10</td><td>Indra</td><td>70</td><td>43000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "Jyoti",
         "25",
         "50000"
        ],
        [
         "2",
         "Albert",
         "30",
         "60000"
        ],
        [
         "3",
         "Baby",
         "35",
         "55000"
        ],
        [
         "4",
         "Chethan",
         "40",
         "70000"
        ],
        [
         "5",
         "David",
         "45",
         "45000"
        ],
        [
         "6",
         "Elango",
         "50",
         "25000"
        ],
        [
         "7",
         "Firoj",
         "55",
         "15000"
        ],
        [
         "8",
         "Giri",
         "60",
         "28000"
        ],
        [
         "9",
         "Hemanth",
         "65",
         "38000"
        ],
        [
         "10",
         "Indra",
         "70",
         "43000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salry",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratio_10 = (\n",
    "    spark.read\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .option(\"samplingRatio\", 0.1) # <-- only 10% rows used to infer schema\n",
    "        .csv(\"/Volumes/@azureadb/pyspark/dataframe/inferschema.csv\")\n",
    ")\n",
    "\n",
    "display(df_ratio_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5b8ec60-a7f3-4d5b-b915-613121cace3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### c) Small ratio (1%) for huge dataset\n",
    "- **Performance gain:** up to **10x faster** schema inference.\n",
    "- **Risk:** If your **1%** sample **doesn’t contain all data patterns**, types might be **wrong**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbe40d69-2779-463a-8d1d-fe00a5a05588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th><th>salry</th></tr></thead><tbody><tr><td>1</td><td>Jyoti</td><td>25</td><td>50000</td></tr><tr><td>2</td><td>Albert</td><td>30</td><td>60000</td></tr><tr><td>3</td><td>Baby</td><td>35</td><td>55000</td></tr><tr><td>4</td><td>Chethan</td><td>40</td><td>70000</td></tr><tr><td>5</td><td>David</td><td>45</td><td>45000</td></tr><tr><td>6</td><td>Elango</td><td>50</td><td>25000</td></tr><tr><td>7</td><td>Firoj</td><td>55</td><td>15000</td></tr><tr><td>8</td><td>Giri</td><td>60</td><td>28000</td></tr><tr><td>9</td><td>Hemanth</td><td>65</td><td>38000</td></tr><tr><td>10</td><td>Indra</td><td>70</td><td>43000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "Jyoti",
         "25",
         "50000"
        ],
        [
         "2",
         "Albert",
         "30",
         "60000"
        ],
        [
         "3",
         "Baby",
         "35",
         "55000"
        ],
        [
         "4",
         "Chethan",
         "40",
         "70000"
        ],
        [
         "5",
         "David",
         "45",
         "45000"
        ],
        [
         "6",
         "Elango",
         "50",
         "25000"
        ],
        [
         "7",
         "Firoj",
         "55",
         "15000"
        ],
        [
         "8",
         "Giri",
         "60",
         "28000"
        ],
        [
         "9",
         "Hemanth",
         "65",
         "38000"
        ],
        [
         "10",
         "Indra",
         "70",
         "43000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salry",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratio_1 = (\n",
    "    spark.read\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .option(\"samplingRatio\", 0.01)\n",
    "        .csv(\"/Volumes/@azureadb/pyspark/dataframe/inferschema.csv\")\n",
    ")\n",
    "\n",
    "display(df_ratio_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5f3de0-cfc9-4b6e-8a3f-c25bd54fee40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Compare Results**\n",
    "\n",
    "| Sampling Ratio | Rows Scanned   | Code                             | Accuracy                   | Speed      |\n",
    "| -------------- | ---------------|--------------------------------- | -------------------------- | ---------- |\n",
    "| 1.0            | 100%           |Default (no samplingRatio) `.option(\"samplingRatio\", 1.0)`   | ✅ Most accurate           | \uD83D\uDC22 Slowest |\n",
    "| 0.1            | 10%            |`.option(\"samplingRatio\", 0.1)`   | ⚖️ Good balance (Sometimes less accurate if rare types exist in skipped rows)  | ⚡ Fast  |\n",
    "| 0.01           | 1%             |`.option(\"samplingRatio\", 0.01)`  | ⚠️ May misinfer some types | \uD83D\uDE80 Fastest |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a8d9a7b-fb53-447b-a556-a0d6314f2769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### d) Observe schema difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "758e39ab-d348-44b2-84d5-5256949bd3d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| age column |\n",
    "|------------|\n",
    "| 10 |\n",
    "| 20 |\n",
    "| 30 |\n",
    "| N/A |\n",
    "| 45.5 |\n",
    "\n",
    "If Spark samples only first 3 rows (integers), it might infer:\n",
    "\n",
    "     |-- age: integer (nullable = true)\n",
    "\n",
    "But in full dataset, 45.5 should make it:\n",
    "\n",
    "     |-- age: double (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1beabc1-3801-49f7-acb7-66b9ad7b40ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Best Practice Recommendations\n",
    "\n",
    "| Use Case                     | Recommended samplingRatio                    |\n",
    "| ---------------------------- | -------------------------------------------- |\n",
    "| Small dataset (<100 MB)      | `1.0` (no sampling)                          |\n",
    "| Medium dataset (100 MB–1 GB) | `0.2` or `0.3`                               |\n",
    "| Large dataset (>1 GB)        | `0.05` to `0.1`                              |\n",
    "| Very large dataset (>10 GB)  | `0.01` or less, but validate schema manually |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2dc7197-758a-4184-acf1-9a21e7195eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2) For JSON file**\n",
    "- Spark will **sample 5%** of **big_data.json** to determine column **data types**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a5c43f2-f473-4a8c-b654-f8e4b24098f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     df_json = (\n",
    "         spark.read\n",
    "              .option(\"inferSchema\", True)\n",
    "              .option(\"samplingRatio\", 0.05)\n",
    "              .json(\"big_data.json\")\n",
    "     )\n",
    "\n",
    "     df_json.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c400be-0550-4a8f-9839-a59ed03bf085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3) With Parquet (ignored)**\n",
    "- For Parquet, this **option has no effect**, because Parquet files **already store schema** in metadata.\n",
    "- You **don’t** need **inferSchema or samplingRatio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a5fb6cb-e411-4ec7-90e2-137cfd2b6744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     df_parquet = (\n",
    "         spark.read\n",
    "              .option(\"samplingRatio\", 0.1)\n",
    "              .parquet(\"data.parquet\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0b97a8c-7f89-40c7-86c1-0b9e2f0df687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### 4) When samplingRatio helps performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "484d95ca-3271-4d88-b9bb-04094a4d4bfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Let’s simulate a big dataset:\n",
    "     df = spark.range(0, 10000000).withColumnRenamed(\"id\", \"age\")\n",
    "     df.write.csv(\"huge_file.csv\", header=True)\n",
    "\n",
    "##### Now, read with full and sampled schema inference:\n",
    "     \n",
    "     # Full scan (slow)\n",
    "     df_full = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"huge_file.csv\")\n",
    "\n",
    "     # 5% sample scan (faster)\n",
    "     df_sample = spark.read.option(\"header\", True).option(\"inferSchema\", True).option(\"samplingRatio\", 0.05).csv(\"huge_file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968ea262-7da4-4072-b2ea-440f23288d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Result**\n",
    "\n",
    "| Setting              | Inference Time (approx) | Accuracy                                      |\n",
    "| -------------------- | ----------------------- | --------------------------------------------- |\n",
    "| No samplingRatio     | 12–15 sec               | ✅ 100% accurate                               |\n",
    "| samplingRatio = 0.05 | 3–4 sec                 | ✅ Same accuracy (since all numeric)           |\n",
    "| samplingRatio = 0.01 | 1–2 sec                 | ⚠️ Slight risk of mis-inference if mixed data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c95e9ce-491f-4d59-99d5-87d6d7934fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Best Practice:\n",
    "**when:**\n",
    "- **File is large**,\n",
    "- You need **quicker schema inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b11b51ad-be73-405b-a047-e8db1d8e1ea3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "     spark.read.option(\"header\", True).option(\"inferSchema\", True).option(\"samplingRatio\", 0.1).csv(\"data.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "44_How to inferSchema using samplingRatio while read files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}