PySpark
-------

1. Dataframe Functions: show in databricks | Azure Databricks | #pyspark PART 01

2. Dataframe Functions: schema, count, describe, summary | Azure Databricks | #pyspark PART 02

3. Databricks|Pyspark: head, show, collect, explain, limit, first, tail & display | #pyspark PART 03

4. Databricks | Pyspark: Collect() function | #pyspark PART 04

5. Databricks | Pyspark: collect_list, collect_set  and array_distinct() | #pyspark  PART 05

6. Databricks | Pyspark: collect_list on multiple columns | #pyspark | PART 06

7. Databricks | Pyspark: struct function | #pyspark PART 07

8. How to filter boolean values using BooleanType | #pyspark PART 08

10. Databricks | Pyspark: lit() function | #pyspark PART 10

11. Databricks | Pyspark: Explode on Array & Map Types | #pyspark PART 11

12. Databricks | Pyspark: Difference b/n Explode and Explode_Outer | #pyspark PART 12

13. Databricks | Pyspark: Difference b/n posexplode and posexplode_outer | #pyspark PART 13

14. Databricks | Pyspark: flatten Array of Array into rows  | #pyspark PART 14

19. Databricks | Pyspark: How to change Column Data type using cast() | #pyspark PART 19

20. date_format( ) | to_date( ) | to_timestamp( ) | date to string & string to date #pyspark PART 20

21. How to convert string to date format using to_date? #pyspark PART 21

22. How to convert Unix Time milli-seconds to Timestamp using timestamp_millis? #pyspark PART 22

23. How to convert Unix Time Seconds to Date and Timestamp using from_unixtime? #pyspark PART 23

24. How to convert date/string/timestamp to epoch seconds using unix_timestamp()? | #pyspark PART 24

25. How to convert string, date type columns to timestamp using to_timestamp()? |#pyspark PART 25

26. How to add metadata columns using current_date, current_user,current_timestamp | #pyspark PART26

30. How to read different JSON file formats using PySpark? #pyspark PART 30

41. How to convert StructType column into StringType using to_json? | #pyspark PART 41

